{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import softmax\n",
    "\n",
    "class AttentionModule(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(AttentionModule, self).__init__()\n",
    "        self.lin = nn.Linear(in_features, out_features, bias=False)\n",
    "        self.att = nn.Parameter(torch.Tensor(1, out_features))\n",
    "        nn.init.xavier_uniform_(self.att.data)\n",
    "\n",
    "    def forward(self, x, index):\n",
    "        x = self.lin(x)\n",
    "        alpha = (x * self.att).sum(dim=-1)\n",
    "        alpha = softmax(alpha, index=index)  # Pass the index to softmax\n",
    "        return alpha\n",
    "\n",
    "\n",
    "class StarMultigraphGNN(MessagePassing):\n",
    "    def __init__(self, edge_features, hidden_dim, num_classes, num_heads=4):\n",
    "        super(StarMultigraphGNN, self).__init__(aggr=\"add\")\n",
    "        self.edge_embed = nn.Linear(edge_features, hidden_dim)\n",
    "        self.attention = nn.ModuleList(\n",
    "            [AttentionModule(hidden_dim, hidden_dim) for _ in range(num_heads)]\n",
    "        )\n",
    "        self.combine = nn.Linear(num_heads * hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "    def forward(self, edge_index, edge_attr, edge_id, num_nodes):\n",
    "        # Embed edge features\n",
    "        edge_emb = self.edge_embed(edge_attr)\n",
    "\n",
    "        # Perform message passing with attention\n",
    "        x = self.propagate(\n",
    "            edge_index, x=None, edge_attr=edge_emb, size=(num_nodes, num_nodes)\n",
    "        )\n",
    "\n",
    "        # Get center node features (assuming center node is 0)\n",
    "        center_node_feat = x[0].unsqueeze(0)\n",
    "\n",
    "        # Classification\n",
    "        out = self.fc(center_node_feat)\n",
    "        return F.log_softmax(out, dim=1)\n",
    "\n",
    "    def message(self, edge_attr, index):\n",
    "        # Apply multi-head attention\n",
    "        alpha_list = [att(edge_attr, index=index) for att in self.attention]\n",
    "        message_list = [alpha.unsqueeze(-1) * edge_attr for alpha in alpha_list]\n",
    "\n",
    "        # Concatenate messages from all heads\n",
    "        return torch.cat(message_list, dim=-1)\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # Combine information from all heads\n",
    "        return self.combine(aggr_out)\n",
    "\n",
    "\n",
    "# Sử dụng mô hình\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score~\n",
    "\n",
    "# Load graph data and labels\n",
    "directories = [\"Star_graph/*/*.pt\"]\n",
    "file_count = {}\n",
    "nodes_data = []\n",
    "y = []\n",
    "\n",
    "for directory in directories:\n",
    "    file_paths = glob.glob(directory)\n",
    "    file_count[directory] = len(file_paths)\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        graph = torch.load(file_path)\n",
    "        y.append(graph.y)\n",
    "        edge_features = graph.edge_attr.size(1)\n",
    "        model = StarMultigraphGNN(\n",
    "            edge_features=edge_features, hidden_dim=64, num_classes=5, num_heads=8\n",
    "        )\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            output = model(\n",
    "                graph.edge_index,\n",
    "                graph.edge_attr,\n",
    "                graph.edge_id,\n",
    "                graph.num_nodes,\n",
    "            )\n",
    "        nodes_data.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[    0.0000, -1422.3243,  -682.8345, -1811.3981, -2239.2217]]),\n",
       " tensor([[ -1075.9932,      0.0000,  -4922.2939,   -734.7773, -12259.6328]]),\n",
       " tensor([[-8687.9316,     0.0000, -2411.6318, -4465.9526, -8970.2002]]),\n",
       " tensor([[-4327.2974, -2037.3149, -4354.1025, -1582.3090,     0.0000]]),\n",
       " tensor([[-209605.6094,  -97140.6094, -196810.7188,       0.0000,  -32785.5898]]),\n",
       " tensor([[-4529.0195, -5952.1895, -6149.6050, -4639.3848,     0.0000]]),\n",
       " tensor([[-3620.0063,     0.0000, -3406.4004, -2411.2002, -6358.5322]]),\n",
       " tensor([[ -2062.1094,      0.0000,  -5391.1646, -49216.2031,   -486.3516]]),\n",
       " tensor([[-32581.6211, -56352.1953,   -152.5371, -33563.4375,      0.0000]]),\n",
       " tensor([[-120953.6875,       0.0000, -116522.9688,  -48953.5195, -123253.5469]]),\n",
       " tensor([[-3080.6008, -2926.9260, -3966.5474, -6966.1133,     0.0000]]),\n",
       " tensor([[-4821.4531, -3181.0488,     0.0000, -9711.3672, -5496.1895]]),\n",
       " tensor([[ -446.2107, -3878.2471, -2578.9648,  -373.5422,     0.0000]]),\n",
       " tensor([[-400874.8750, -469291.1250, -112345.3750, -180811.0781,       0.0000]]),\n",
       " tensor([[    0.0000, -2150.5259, -1294.2588, -4927.0972,  -943.8637]]),\n",
       " tensor([[-7912.6924, -5764.5000,  -956.4020,  -516.9536,     0.0000]]),\n",
       " tensor([[ -7303.2549,  -5712.0591,  -5552.4893,      0.0000, -16621.7305]]),\n",
       " tensor([[-1244.4626,     0.0000, -2285.9341, -5028.6992, -4214.7568]]),\n",
       " tensor([[-17565.2617, -14814.3828,   -105.6787, -24442.9355,      0.0000]]),\n",
       " tensor([[     0.0000,  -8069.2192,  -1781.2549,  -8477.5332, -18694.9023]]),\n",
       " tensor([[      0.0000,  -52797.7500, -663622.7500, -795208.7500, -583733.3750]]),\n",
       " tensor([[    0.0000, -2575.8284, -1894.5581, -1127.5032, -2190.9084]]),\n",
       " tensor([[-2725.6101,  -930.3240,  -715.5563,     0.0000, -3604.3625]]),\n",
       " tensor([[-8610.9297, -2532.0901,     0.0000, -4132.5913, -6334.4131]]),\n",
       " tensor([[ -306.9684,     0.0000, -3002.0129, -3083.7439,  -111.3240]]),\n",
       " tensor([[-15170.3398, -24164.7617, -19824.2363, -20481.1094,      0.0000]]),\n",
       " tensor([[-6608985.5000, -4250334.0000,        0.0000,  -125192.2500,\n",
       "          -4321790.0000]]),\n",
       " tensor([[ -320624.9062, -1694786.8750,  -816078.3125,  -456284.0938,\n",
       "                 0.0000]]),\n",
       " tensor([[-4243.1582, -5570.0859,     0.0000, -6648.7490, -3442.0583]]),\n",
       " tensor([[-2591.0659, -3113.9790,  -994.3062,     0.0000, -6160.0439]]),\n",
       " tensor([[-95362.2344, -47945.9688, -55147.0430, -55330.5938,      0.0000]]),\n",
       " tensor([[-2269035.0000, -2506362.5000,        0.0000, -3940436.0000,\n",
       "           -367685.7188]]),\n",
       " tensor([[-22876.5566, -52587.5078,      0.0000, -33073.1133, -41028.7812]]),\n",
       " tensor([[ -752619.1875,  -370033.7500,        0.0000,  -644890.6250,\n",
       "          -1228331.6250]]),\n",
       " tensor([[ -695221.0625,        0.0000,  -704942.0625, -1126996.7500,\n",
       "          -1405634.2500]]),\n",
       " tensor([[ -9175924., -15852146.,  -4670985., -11643670.,         0.]]),\n",
       " tensor([[ -981.4335,     0.0000,  -312.4541,  -333.9385, -5134.1836]]),\n",
       " tensor([[-5318.2427,     0.0000, -1741.9976, -3552.6172, -6832.9336]]),\n",
       " tensor([[ -263042.6875, -1020371.2500,        0.0000,  -512134.9688,\n",
       "           -461428.4375]]),\n",
       " tensor([[ -317834.4688,  -295392.3438,   -55752.8125,        0.0000,\n",
       "          -1198791.0000]]),\n",
       " tensor([[-1438145.7500,        0.0000, -1817841.5000, -1148029.2500,\n",
       "          -2213591.5000]]),\n",
       " tensor([[-2768685.5000, -3111398.0000, -9177186.0000, -7772614.0000,\n",
       "                 0.0000]]),\n",
       " tensor([[     0.0000,  -6158.0615, -23056.4219,  -3794.2219,  -1192.3611]]),\n",
       " tensor([[    0.0000, -7057.3887, -5557.6665, -1138.8931, -6223.0635]]),\n",
       " tensor([[-66303.3281, -23424.1836,      0.0000, -42854.2305, -57481.3750]]),\n",
       " tensor([[-564229.4375,  -65307.6172,       0.0000, -259963.3750, -556559.8125]]),\n",
       " tensor([[     0.0000, -25493.6914,  -8847.9707, -31613.9277, -19075.9844]]),\n",
       " tensor([[-2989.8999, -7231.5068,     0.0000, -7012.5859, -2643.4170]]),\n",
       " tensor([[-73996.8828, -31165.9219, -14747.2109,      0.0000, -57456.6562]]),\n",
       " tensor([[ -3431.1387, -12668.9941, -16491.4102, -17016.2852,      0.0000]]),\n",
       " tensor([[ -98513.2812, -454090.3125,  -33049.6250, -245368.4688,       0.0000]]),\n",
       " tensor([[    0.0000, -7838.8027, -7650.5254,  -401.1514, -8315.9863]]),\n",
       " tensor([[ -68553.0547,       0.0000, -119291.5547, -206429.7188,   -9680.5703]]),\n",
       " tensor([[-235729.4062,   -3246.5156,  -98264.6641, -179453.2812,       0.0000]]),\n",
       " tensor([[-1410.0371, -2390.0667, -2689.0854,     0.0000, -1309.6888]]),\n",
       " tensor([[    0.0000, -1419.1016, -1375.4570,  -954.1328, -2999.2739]]),\n",
       " tensor([[-1001786.8750,   -97496.8750,  -358118.6250,        0.0000,\n",
       "           -915599.4375]]),\n",
       " tensor([[    0.0000,  -806.0202, -2066.5171,  -564.2209,  -217.8096]]),\n",
       " tensor([[-18978.4785, -12445.9258,  -8295.1621,  -5971.4546,      0.0000]]),\n",
       " tensor([[-6736.8135,     0.0000, -4566.7866, -4610.4541, -3761.9539]]),\n",
       " tensor([[-3866.7156,     0.0000,  -938.8083,   -64.4970, -3544.0754]]),\n",
       " tensor([[-3054.5671, -2303.6719,     0.0000, -1581.6832, -4311.2710]]),\n",
       " tensor([[       0.0000, -1261075.5000, -2540177.0000, -2043357.0000,\n",
       "          -2711010.2500]]),\n",
       " tensor([[-2938.2722, -4927.1504, -1954.6362, -2044.4540,     0.0000]]),\n",
       " tensor([[     0.0000, -82530.1484, -17696.5410, -43594.7305, -29648.4258]]),\n",
       " tensor([[-4480091.5000, -3963130.0000,        0.0000, -3951765.5000,\n",
       "          -3032641.7500]]),\n",
       " tensor([[    0.0000, -1479.0123,  -744.3434,  -233.7802, -1116.0847]]),\n",
       " tensor([[-2041.3950,  -456.9773,  -959.3700,     0.0000,  -479.9866]]),\n",
       " tensor([[ -66560.3672,   -2613.9297,       0.0000,  -33548.7734, -143424.4531]]),\n",
       " tensor([[-2269.7710,  -881.0642,  -294.5194, -3136.6743,     0.0000]]),\n",
       " tensor([[-4260320.0000, -1208161.1250, -2752892.7500,        0.0000,\n",
       "          -1628748.6250]]),\n",
       " tensor([[ -3393.7329,  -2592.7278,  -2318.6252, -12804.4434,      0.0000]]),\n",
       " tensor([[-19521454., -16090472., -10453528.,         0.,  -9400287.]]),\n",
       " tensor([[-15844723., -15182674., -20270276.,         0.,  -5881471.]]),\n",
       " tensor([[      0.0000,  -32050.6113,  -31310.7656,  -60315.9219, -106099.4844]]),\n",
       " tensor([[      0.0000, -145422.4844, -100206.6641, -137165.4219, -317745.0625]]),\n",
       " tensor([[-2602.4209, -1399.4390, -1053.5076,     0.0000,  -326.8655]]),\n",
       " tensor([[-10743.9609,      0.0000, -17822.9570, -12533.7354, -12565.2852]]),\n",
       " tensor([[-3192.7070, -3036.2112, -7621.7407,     0.0000, -3624.9502]]),\n",
       " tensor([[-86442.6641, -21110.6582, -29189.1875,      0.0000, -66003.2500]]),\n",
       " tensor([[    0.0000, -6837.4019, -2917.4404, -4474.9062, -3453.1538]]),\n",
       " tensor([[-3331.2422, -1105.5896,     0.0000, -1344.4679,  -611.5145]]),\n",
       " tensor([[-5393.4336, -5166.4849,     0.0000, -1438.8358, -2549.0977]]),\n",
       " tensor([[-25015.4785, -32818.2070, -31781.0938,  -3314.1677,      0.0000]]),\n",
       " tensor([[-2000692.5000,        0.0000, -4550812.0000,  -749658.6250,\n",
       "          -5639550.5000]]),\n",
       " tensor([[ -479.9978,     0.0000, -5270.1572, -6406.9854, -2492.6396]]),\n",
       " tensor([[-175577.7812,       0.0000,  -69503.2422,  -58964.6133, -174528.8438]]),\n",
       " tensor([[    0.0000, -1384.1797, -3814.4712, -2938.0308, -2973.5786]]),\n",
       " tensor([[-1025.0796,     0.0000, -7062.1455, -6950.0762, -3661.8726]]),\n",
       " tensor([[-5167.0327, -2211.1411,     0.0000, -5700.4746, -2614.9255]]),\n",
       " tensor([[      0.0000, -139824.0938, -304168.6875, -289480.8750, -227091.5000]]),\n",
       " tensor([[ -383442.7500,  -826823.4375, -1914566.1250, -2564334.7500,\n",
       "                 0.0000]]),\n",
       " tensor([[ -9509.6895,  -5819.8174, -26013.2070,      0.0000,  -5532.1436]]),\n",
       " tensor([[      0.0000, -140615.0469, -255813.2188, -214285.3750, -168446.8125]]),\n",
       " tensor([[-107154.8594,  -23252.7852,       0.0000,  -62597.7500, -136068.3438]]),\n",
       " tensor([[    0.0000, -2702.3245, -2839.6047,  -795.1542,  -382.9150]]),\n",
       " tensor([[ -96391.6406, -228171.4375,  -14731.7305,       0.0000, -104379.8984]]),\n",
       " tensor([[-3141246.0000,  -747973.3750, -2231462.0000,  -396141.8125,\n",
       "                 0.0000]]),\n",
       " tensor([[    0.0000, -1090.8878, -1278.2744, -1238.0502, -1119.4354]]),\n",
       " tensor([[-2020276.7500, -3831460.2500,        0.0000, -4021757.7500,\n",
       "          -6004078.0000]]),\n",
       " tensor([[-136713.4531, -888846.2500,       0.0000, -535752.8125, -835027.3125]]),\n",
       " tensor([[-1843.6711,   -21.4135,  -399.1241,     0.0000, -1715.9655]]),\n",
       " tensor([[-827576.5000,       0.0000, -467210.5000, -647462.8750, -760159.1250]]),\n",
       " tensor([[-10636.5293,   -443.7529,  -4181.9429,  -9568.2510,      0.0000]]),\n",
       " tensor([[       0.0000, -5646846.0000, -6950780.0000, -2685887.0000,\n",
       "          -2250513.2500]]),\n",
       " tensor([[-2945.0889,  -694.4497, -2636.9009, -3275.4614,     0.0000]]),\n",
       " tensor([[-105991.0781,  -63626.5820, -119118.9531,       0.0000, -153966.7500]]),\n",
       " tensor([[ -94461.4844,  -48300.4297,   -6534.8398, -114419.6406,       0.0000]]),\n",
       " tensor([[-121095.7812,       0.0000,   -2878.8047, -156043.1406, -135812.5312]]),\n",
       " tensor([[-1466321.6250, -1465783.5000, -1628833.3750,        0.0000,\n",
       "           -850912.2500]]),\n",
       " tensor([[-5394.5010, -6077.6172, -1287.6667,     0.0000, -4385.7339]]),\n",
       " tensor([[-13539.8809,      0.0000, -74179.2109, -53600.1484, -56774.6641]]),\n",
       " tensor([[-5496.8799, -6096.6729, -4209.5312, -8787.0137,     0.0000]]),\n",
       " tensor([[-2334553.0000, -7205377.0000,  -405909.2500,        0.0000,\n",
       "          -3150665.5000]]),\n",
       " tensor([[ -99755.7109, -148526.6719, -218986.7031,       0.0000,  -52223.0820]]),\n",
       " tensor([[     0.0000, -54373.4492, -63476.3398, -26370.3008, -22094.4609]]),\n",
       " tensor([[ -928860.6875,        0.0000,  -997207.6875, -1598659.8750,\n",
       "          -1229524.6250]]),\n",
       " tensor([[-105474.8047,  -68378.0781,   -3701.9922,  -56127.2109,       0.0000]]),\n",
       " tensor([[-2380.3862,     0.0000, -2284.7007, -2630.5049,  -349.4595]]),\n",
       " tensor([[     0.0000, -89411.2578, -66028.6172, -90393.7734, -74040.5234]]),\n",
       " tensor([[       0.0000, -6316270.0000,  -835798.3750, -2830432.2500,\n",
       "           -800509.0000]]),\n",
       " tensor([[-116030.4531, -153358.5938,  -33582.8281, -168326.4062,       0.0000]]),\n",
       " tensor([[      0.0000, -144952.0781,  -69326.3750,  -65616.0391, -183948.8750]]),\n",
       " tensor([[  -31132.4375, -2417720.5000,        0.0000,  -105704.3125,\n",
       "          -1842882.0000]]),\n",
       " tensor([[-15604.3174,      0.0000, -73446.0547,  -4186.8340, -23677.8164]]),\n",
       " tensor([[-249186.4688, -111848.2344,       0.0000, -121152.1094, -171878.5469]]),\n",
       " tensor([[-2928424.2500, -7045080.0000, -4240403.5000, -3236448.7500,\n",
       "                 0.0000]]),\n",
       " tensor([[      0.0000, -256949.5938, -174791.7812, -158084.4062,  -65941.2344]]),\n",
       " tensor([[-153001.2500, -225888.1719,       0.0000, -214644.9062, -199459.2188]]),\n",
       " tensor([[-2332059.5000,        0.0000, -2252611.0000,  -424683.7500,\n",
       "          -1435757.0000]]),\n",
       " tensor([[-2088054.0000,        0.0000, -2506509.5000,  -930174.0000,\n",
       "           -751063.3125]]),\n",
       " tensor([[-1006.4885, -3954.7227, -3151.0273,     0.0000,  -726.2472]]),\n",
       " tensor([[ -5806.9160, -21439.4336,  -3548.4321,  -5472.2646,      0.0000]]),\n",
       " tensor([[ -73046.5312, -140396.5781, -116509.5000,   -7295.1875,       0.0000]]),\n",
       " tensor([[      0.0000, -158043.0938,  -57561.3672,  -48961.1992, -199006.2344]]),\n",
       " tensor([[ -41744.7305,  -67742.4453, -319455.2812,       0.0000,  -27857.1914]]),\n",
       " tensor([[-19182.1152, -23766.6914, -12190.0254, -10928.5469,      0.0000]]),\n",
       " tensor([[-1970950.2500,        0.0000,  -247051.0000,  -497901.2500,\n",
       "           -297038.7500]]),\n",
       " tensor([[-5179710.5000, -3370665.5000, -3909605.5000,        0.0000,\n",
       "          -2515966.5000]]),\n",
       " tensor([[  -770.4048,      0.0000, -47555.8906, -27339.0918, -14339.1582]]),\n",
       " tensor([[-1443.4403, -2944.0239,     0.0000,  -494.7560, -2120.7717]]),\n",
       " tensor([[-1752472.7500,  -447153.6250,        0.0000, -2724726.7500,\n",
       "          -2334388.0000]]),\n",
       " tensor([[-5091184.0000, -1860273.0000, -4889309.0000, -3887154.5000,\n",
       "                 0.0000]]),\n",
       " tensor([[-3265.0894, -1339.3607,     0.0000, -1121.2122, -2899.5820]]),\n",
       " tensor([[    0.0000, -3856.3223, -1930.5918, -2215.1270, -4125.9595]]),\n",
       " tensor([[ -8263.9023,  -7144.2051,      0.0000, -16480.3906,  -6479.9971]]),\n",
       " tensor([[-1030366.3125,        0.0000, -1925069.8750, -2367966.0000,\n",
       "           -608157.2500]]),\n",
       " tensor([[-2856.7646,  -343.6884, -2875.5535, -1791.2217,     0.0000]]),\n",
       " tensor([[-103329.0938,  -19082.3477,  -47109.3594,       0.0000,  -31225.3164]]),\n",
       " tensor([[-30685.1133, -23613.6328,      0.0000, -14252.8828, -17523.0078]]),\n",
       " tensor([[-10470.4980, -10474.2197,      0.0000, -13126.4531, -10836.9277]]),\n",
       " tensor([[-15199.0439,  -4004.5635, -51406.4062,      0.0000, -13988.2637]]),\n",
       " tensor([[ -58720.3281,  -57622.4531,       0.0000, -175791.1406, -242043.6250]]),\n",
       " tensor([[-22661.4727,  -8677.4766, -42035.7539,      0.0000, -43030.2266]]),\n",
       " tensor([[-2848258.7500, -2358256.5000,        0.0000, -1995378.7500,\n",
       "          -5109433.0000]]),\n",
       " tensor([[-4189.8667, -1347.8766,     0.0000, -1746.2142, -1050.0028]]),\n",
       " tensor([[-1925415.5000, -2632451.5000,        0.0000, -2995563.5000,\n",
       "          -2584490.2500]]),\n",
       " tensor([[ -58994.9219,       0.0000,  -74750.8906, -114672.0156,  -36008.7109]]),\n",
       " tensor([[-186339.5781,   -8711.7578, -120079.7969, -234809.1562,       0.0000]]),\n",
       " tensor([[ -74439.5703,  -78984.5469, -130768.9141, -283001.6875,       0.0000]]),\n",
       " tensor([[ -51958.0859,  -33379.3047,  -84689.0938, -206996.9219,       0.0000]]),\n",
       " tensor([[     0.0000,  -2727.0591,  -3862.1553, -11876.2041, -10986.6738]]),\n",
       " tensor([[-806211.1875, -350181.1875, -153266.0000, -146981.6875,       0.0000]]),\n",
       " tensor([[    0.0000, -2018.6921, -1150.8792, -2198.1118,  -498.9869]]),\n",
       " tensor([[      0.0000, -264586.0625, -236851.5938, -100690.8281, -232392.1562]]),\n",
       " tensor([[-4502.8955,     0.0000, -4238.9058, -1208.7305, -1088.2883]]),\n",
       " tensor([[-164827.6094,  -31088.2148,       0.0000, -225197.3125, -123339.8125]]),\n",
       " tensor([[ -68852.7344, -197910.9219, -357119.2500,       0.0000, -227356.3594]]),\n",
       " tensor([[     0.0000, -57099.9844, -31761.1758, -66470.1094, -32668.2793]]),\n",
       " tensor([[-3075550.7500, -1696190.5000,        0.0000, -3523657.5000,\n",
       "          -2560590.5000]]),\n",
       " tensor([[       0.0000, -4257120.0000, -2011241.2500, -4010531.7500,\n",
       "          -3089425.2500]]),\n",
       " tensor([[      0.0000,  -50305.7031, -149927.1250, -487960.3438, -222293.6875]]),\n",
       " tensor([[-4162899.0000, -4483897.0000, -4723342.5000, -4542048.0000,\n",
       "                 0.0000]]),\n",
       " tensor([[-403546.5000, -165288.6250,  -63193.0859,       0.0000, -456069.3750]]),\n",
       " tensor([[    0.0000, -5434.3584, -2889.1934, -2772.3579, -4376.3311]]),\n",
       " tensor([[-673959.8750,       0.0000, -662609.1250, -625784.5625,  -22179.6250]]),\n",
       " tensor([[-15712.9980, -21891.2188,      0.0000, -40130.4531, -39863.4844]]),\n",
       " tensor([[-23590.9492,      0.0000, -77029.8047, -22302.8281, -35491.4961]]),\n",
       " tensor([[ -705.6868, -3711.3398, -4148.2612, -1331.1705,     0.0000]]),\n",
       " tensor([[ -73432.2500, -135694.0000, -184876.0156,  -21862.3027,       0.0000]]),\n",
       " tensor([[      0.0000, -173180.9688, -253704.5312, -235729.7656, -453241.0625]]),\n",
       " tensor([[ -1747.2026,  -1753.7751,      0.0000, -10440.2998,  -1206.5071]]),\n",
       " tensor([[      0.0000,  -98791.0234,  -32742.3516, -110906.8516, -128634.3516]]),\n",
       " tensor([[      0.0000,  -62009.5195, -151268.6562, -114399.1562, -206859.8438]]),\n",
       " tensor([[       0.0000, -2056601.5000,  -148220.5000, -2534147.0000,\n",
       "          -2932358.7500]]),\n",
       " tensor([[-78841.3281, -39508.1875, -68922.8203,  -1827.1719,      0.0000]]),\n",
       " tensor([[-116024.3828,       0.0000, -111747.0469, -284799.3438, -120923.7500]]),\n",
       " tensor([[    0.0000, -1854.2811, -2608.4478, -1990.5638, -1453.3589]]),\n",
       " tensor([[-1140081.8750, -1562530.2500, -2331326.5000, -3786245.2500,\n",
       "                 0.0000]]),\n",
       " tensor([[ -4159.4297, -65243.2852,      0.0000, -67394.4375,  -7665.4121]]),\n",
       " tensor([[-3161543.0000,  -417365.2500,  -890153.0625, -1900798.0000,\n",
       "                 0.0000]]),\n",
       " tensor([[ -59951.6719, -572954.7500, -141407.9062,       0.0000, -268842.8125]]),\n",
       " tensor([[      0.0000,  -29188.9648, -107934.3750,  -48499.0820, -144458.1250]]),\n",
       " tensor([[-29279.3223, -46613.2344, -66299.4609,      0.0000, -91920.4844]]),\n",
       " tensor([[-1731311.2500, -1631554.0000, -2430083.5000, -1896268.8750,\n",
       "                 0.0000]]),\n",
       " tensor([[-4373314.0000, -1867714.3750,        0.0000, -3987384.7500,\n",
       "           -812535.5000]]),\n",
       " tensor([[ -273501.5625, -1338403.7500,        0.0000, -1371359.6250,\n",
       "          -1120273.5000]]),\n",
       " tensor([[    0.0000, -1508.5728, -3634.9697, -3060.5176, -5689.2651]]),\n",
       " tensor([[ -4069.4395,      0.0000, -16617.4668, -38261.4141, -42395.5273]]),\n",
       " tensor([[-2001013.7500, -3632718.2500, -3454397.5000,        0.0000,\n",
       "          -3119767.0000]]),\n",
       " tensor([[-2413.6858, -2115.9126,     0.0000, -5065.9077, -3890.2878]]),\n",
       " tensor([[-1268.9694,  -441.5247,     0.0000, -1093.6987,  -809.0155]]),\n",
       " tensor([[      0.0000,  -30735.0625, -352385.3750,  -77833.3438, -105541.1484]]),\n",
       " tensor([[-235327.1719, -225768.6875,       0.0000, -361208.6562, -281309.9062]]),\n",
       " tensor([[-18969.8105, -47922.7773, -12571.3164, -18967.1484,      0.0000]]),\n",
       " tensor([[ -53140.9062,  -52957.9102,       0.0000, -103603.0391, -142802.8281]]),\n",
       " tensor([[-4849.8716, -1005.0381,     0.0000,  -500.0020, -3272.1787]]),\n",
       " tensor([[-184594.0938,  -91086.5938, -165069.9062,       0.0000, -152730.9844]]),\n",
       " tensor([[-328116.7188, -185742.1406,       0.0000, -479555.1875, -347819.4062]]),\n",
       " tensor([[-61538.0508, -34113.9883,      0.0000, -39919.3711,  -9211.7930]]),\n",
       " tensor([[-154722.9688,       0.0000,  -88679.5469, -134856.7812,  -71112.0469]]),\n",
       " tensor([[-5514.2886, -6366.1348,     0.0000, -4162.7681, -8112.6406]]),\n",
       " tensor([[-36242.0234,      0.0000, -32575.5059, -68918.2578, -18655.1660]]),\n",
       " tensor([[      0.0000, -209857.7188,  -60821.0625, -176506.4375, -164497.4375]]),\n",
       " tensor([[       0.0000, -1175799.3750,  -828019.7500,  -509837.8125,\n",
       "            -47016.8750]]),\n",
       " tensor([[-152863.8750,  -59516.5547,  -89186.8047,       0.0000,  -39082.9336]]),\n",
       " tensor([[ -786263.8125, -1515895.6250,  -434325.8750, -2308807.5000,\n",
       "                 0.0000]]),\n",
       " tensor([[ -297.0638, -3461.0210,     0.0000, -1346.6268,  -647.7383]]),\n",
       " tensor([[-25215.4883, -19457.5488,      0.0000, -22237.3047, -16388.2441]]),\n",
       " tensor([[-1379661.7500,  -408777.7500, -1229253.5000, -2834924.0000,\n",
       "                 0.0000]]),\n",
       " tensor([[-4285.5605,  -956.8284,  -151.8473, -4984.7798,     0.0000]]),\n",
       " tensor([[-3982899.0000, -2264035.2500,  -808803.5625, -1228564.1250,\n",
       "                 0.0000]]),\n",
       " tensor([[ -97232.3281, -188569.2344,   -1008.6367, -158980.9844,       0.0000]]),\n",
       " tensor([[      0.0000, -199565.0469,  -24738.7422,  -88857.4375, -105349.0000]]),\n",
       " tensor([[       0.0000, -1594228.7500,  -503533.3750, -2114938.2500,\n",
       "          -2601735.0000]]),\n",
       " tensor([[-43934.8125,      0.0000, -40742.0000, -13851.8887, -86191.8281]]),\n",
       " tensor([[     0.0000, -16625.6367,   -139.4092,  -3310.6140,   -570.5923]]),\n",
       " tensor([[-2267827.0000,        0.0000, -1843002.3750, -3623283.2500,\n",
       "          -3788298.0000]]),\n",
       " tensor([[ -88519.0781,  -11284.4062, -153307.9688,  -72809.0391,       0.0000]]),\n",
       " tensor([[-397656.0625, -207372.1875, -254696.3125, -181212.1094,       0.0000]]),\n",
       " tensor([[ -716.2402, -3968.4858, -4629.4971,     0.0000, -5039.6748]]),\n",
       " tensor([[    0.0000, -3415.7214, -2442.9231,  -787.3605, -1884.5818]]),\n",
       " tensor([[ -33378.4219,  -96783.5000,       0.0000, -186782.1094,  -56789.5039]]),\n",
       " tensor([[ -10430.1875, -105343.0000, -193023.5000,       0.0000,  -36666.4805]]),\n",
       " tensor([[-2787.1416, -2871.6409, -5696.0068,     0.0000, -4732.6934]]),\n",
       " tensor([[ -37782.9219, -105225.9688,  -96772.7188,       0.0000, -163727.4375]]),\n",
       " tensor([[       0.0000,  -310487.8438,  -403319.0625,  -382939.5000,\n",
       "          -1039926.8750]]),\n",
       " tensor([[-1694.4746, -1161.9634, -5493.0474, -4058.6565,     0.0000]]),\n",
       " tensor([[      0.0000,  -98479.0391, -234457.6250,  -67684.5781, -291739.1875]]),\n",
       " tensor([[-150896.8125,       0.0000,   -2038.9922,  -42196.7812,  -38750.3516]]),\n",
       " tensor([[      0.0000, -129631.0938,  -35565.3203,  -34267.9375, -178351.4375]]),\n",
       " tensor([[-266983.8125, -105245.0938, -385961.6562,       0.0000, -447364.3125]]),\n",
       " tensor([[      0.0000, -201608.7812, -281661.8438,  -10573.7500, -242942.7812]]),\n",
       " tensor([[-3438.4507, -5232.3931, -4466.7266, -3212.4602,     0.0000]]),\n",
       " tensor([[-2146.5525,     0.0000, -2471.4084, -2735.5156, -5813.4380]]),\n",
       " tensor([[    0.0000, -1889.6594, -1365.9877,  -811.4679, -3772.0029]]),\n",
       " tensor([[-210401.3750,       0.0000, -281001.2188, -148653.0312,  -58731.6953]]),\n",
       " tensor([[-2547.0569,     0.0000,  -310.4695,  -241.2713,  -384.1617]]),\n",
       " tensor([[-322568.5000,  -73709.0156,       0.0000, -282011.1562, -282230.1562]]),\n",
       " tensor([[ -313797.8750, -4232067.5000, -1388828.7500, -4979449.0000,\n",
       "                 0.0000]]),\n",
       " tensor([[      0.0000, -128237.5312, -238591.4375, -138207.7656,  -97500.7656]]),\n",
       " tensor([[ -87166.8047,       0.0000, -139998.2188,  -82263.1484, -138415.1719]]),\n",
       " tensor([[-55947.0859,  -3033.7598,      0.0000, -85602.0000, -42404.9883]]),\n",
       " tensor([[ -657.0903,  -643.9676,     0.0000, -2413.7759,  -436.0148]]),\n",
       " tensor([[-2179.0486, -4697.3174, -3425.4031,     0.0000, -1466.3528]]),\n",
       " tensor([[-1652957.1250, -1898020.6250, -1391893.2500,        0.0000,\n",
       "          -1099783.2500]]),\n",
       " tensor([[-139164.4844,  -19443.1797,  -92599.3984,  -21607.3125,       0.0000]]),\n",
       " tensor([[-194704.0312, -138460.2188,       0.0000, -166654.8125, -213348.3594]]),\n",
       " tensor([[    0.0000, -2566.2266, -3483.5586, -2266.4861,  -550.4852]]),\n",
       " tensor([[-2284723.2500, -2934564.5000,        0.0000, -1687846.5000,\n",
       "           -943324.3750]]),\n",
       " tensor([[-1132537.0000, -2627431.5000, -4029298.5000, -1003494.2500,\n",
       "                 0.0000]]),\n",
       " tensor([[-42840.0508, -44417.4961, -52187.2070, -94733.9375,      0.0000]]),\n",
       " tensor([[       0.0000,  -788794.9375,  -305262.9688, -1160053.0000,\n",
       "          -1067672.3750]]),\n",
       " tensor([[-110084.7031,       0.0000, -113745.1875, -132612.2500,  -73954.9844]]),\n",
       " tensor([[-20325.1074, -22690.5957,      0.0000, -54577.1562, -47904.3047]]),\n",
       " tensor([[ -26681.2852,       0.0000, -122127.9062,  -19777.9453,   -5082.6201]]),\n",
       " tensor([[-1453.2798,     0.0000, -4015.5005, -5204.4321, -3937.1060]]),\n",
       " tensor([[ -89345.0156, -103426.5156, -160568.2500, -239534.5625,       0.0000]]),\n",
       " tensor([[ -73283.4531,  -96336.5078,  -44492.0430,       0.0000, -105090.6875]]),\n",
       " tensor([[      0.0000,  -47462.1484,  -56867.1055, -102458.7422,  -74666.6719]]),\n",
       " tensor([[ -513907.6250, -2720525.0000, -1860076.0000, -2319552.2500,\n",
       "                 0.0000]]),\n",
       " tensor([[ -2879171.7500, -10015170.0000,         0.0000,  -7522051.5000,\n",
       "           -3577368.7500]]),\n",
       " tensor([[ -54544.5898, -100492.5391,       0.0000,  -89041.0312,  -89207.9766]]),\n",
       " tensor([[-39859.5781, -43386.6562, -36545.0938,      0.0000, -59971.5352]]),\n",
       " tensor([[-2635445.2500,        0.0000, -3707688.2500, -4472009.5000,\n",
       "          -2623813.5000]]),\n",
       " tensor([[-113186.1406,  -92615.8047,       0.0000,  -58338.0352, -138553.3281]]),\n",
       " tensor([[-130158.6797, -182706.1562, -153915.2188,       0.0000, -136396.3438]]),\n",
       " tensor([[-8347348.0000, -6644440.0000,        0.0000, -1716601.3750,\n",
       "          -6616731.5000]]),\n",
       " tensor([[ -18344.7656,  -87334.9531,       0.0000, -165355.8906, -108961.6094]]),\n",
       " tensor([[     0.0000, -34269.6953, -61980.4336, -31552.5059, -55319.3203]]),\n",
       " tensor([[ -68246.3281, -152998.3125,       0.0000, -275012.0000, -154003.0781]]),\n",
       " tensor([[     0.0000, -81597.1719, -85623.1406, -63055.6172, -37425.8281]]),\n",
       " tensor([[-3311.4863, -7481.7559,     0.0000, -4932.8311, -5959.7510]]),\n",
       " tensor([[-32357.6953, -17062.9785, -19471.3164, -26595.8438,      0.0000]]),\n",
       " tensor([[ -46494.6211,  -48611.8750, -166899.6250,       0.0000,  -43096.5469]]),\n",
       " tensor([[-10305973.,  -7750815., -16021181., -13644860.,         0.]]),\n",
       " tensor([[ -76455.8125,       0.0000,  -91830.9062,  -76705.3125, -182059.0000]]),\n",
       " tensor([[-1184.5013, -1203.6085, -1498.8467, -3528.3328,     0.0000]]),\n",
       " tensor([[-233517.1562,  -60936.6836,  -34970.5977,  -28658.5352,       0.0000]]),\n",
       " tensor([[-1726309.,        0., -4910800., -1485985., -7366155.]]),\n",
       " tensor([[-3657903.7500, -1702815.7500,        0.0000, -6712707.0000,\n",
       "          -3770147.5000]]),\n",
       " tensor([[ -97665.9062,       0.0000,  -61641.3320, -220048.0469,  -24360.7754]]),\n",
       " tensor([[-23227.1895, -13862.2812,  -6309.5464,      0.0000, -24697.6055]]),\n",
       " tensor([[      0.0000,  -10088.7344,  -58845.2188, -145834.1406, -177419.8125]]),\n",
       " tensor([[-30903.3438, -12052.5820, -90324.2188, -24291.2773,      0.0000]]),\n",
       " tensor([[       0.0000, -8751947.0000, -4071397.5000, -5522197.0000,\n",
       "          -2710424.2500]]),\n",
       " tensor([[     0.0000, -64318.9648,  -5557.5547, -51647.2969, -18337.7520]]),\n",
       " tensor([[ -43593.2656,       0.0000, -162052.0312,  -39120.9062, -127382.9531]]),\n",
       " tensor([[-4036883.5000, -1636523.6250,        0.0000, -3166536.2500,\n",
       "          -7169339.0000]]),\n",
       " tensor([[     0.0000, -68751.7266, -56531.6328, -86215.5469, -68865.5391]]),\n",
       " tensor([[      0.0000,   -3320.9141, -126906.0859,  -54358.6562, -143632.6094]]),\n",
       " tensor([[-58644.0234, -47895.8477, -67449.6641,      0.0000, -86557.0938]]),\n",
       " tensor([[-155194.9844, -142624.7188,       0.0000,  -51197.5195, -109833.5859]]),\n",
       " tensor([[    0.0000, -1058.7628,  -180.8317, -3723.3152, -1444.2061]]),\n",
       " tensor([[-16559.2539,      0.0000, -19827.3125, -27253.5977, -10634.2656]]),\n",
       " tensor([[-2572.4541, -3270.0947,  -848.0887, -4686.3936,     0.0000]]),\n",
       " tensor([[ -632.9534, -4146.6401,     0.0000, -3800.0049,  -922.5938]]),\n",
       " tensor([[-141612.4531, -144433.2500,       0.0000,  -37891.7344, -110821.1406]]),\n",
       " tensor([[-4082.6313, -1311.9822, -2862.9336,     0.0000,  -438.8115]]),\n",
       " tensor([[     0.0000, -29537.9336, -40062.3750, -66242.0312, -21780.7207]]),\n",
       " tensor([[      0.0000, -192156.4062,  -45108.8828,   -9778.0508,  -79256.5000]]),\n",
       " tensor([[-39834.3320, -76860.0859,  -2201.4609,      0.0000, -30325.2266]]),\n",
       " tensor([[ -54375.8203,       0.0000,  -90935.9844, -135718.8594,  -35716.2109]]),\n",
       " tensor([[-40482.3750, -31825.8320, -87932.6172, -91154.2969,      0.0000]]),\n",
       " tensor([[-56249.1289, -39642.7812,      0.0000, -12913.9854,  -9198.3896]]),\n",
       " tensor([[-3422.9883, -1855.8916,     0.0000, -3271.8928, -1060.1333]]),\n",
       " tensor([[-2040666.1250, -2008900.7500, -2949990.5000,        0.0000,\n",
       "          -3026134.5000]]),\n",
       " tensor([[    0.0000, -4829.5146, -4035.5564, -2127.7646,  -589.0935]]),\n",
       " tensor([[-3051.0815, -2550.0369, -3742.0322, -1466.2090,     0.0000]]),\n",
       " tensor([[      0.0000,  -34291.4805, -177403.2031, -125669.6016,  -48579.7930]]),\n",
       " tensor([[ -6469.9355, -15919.1963, -43954.0156,      0.0000, -25938.3418]]),\n",
       " tensor([[ -51614.1602, -172325.7500, -145545.2031,       0.0000, -169258.7031]]),\n",
       " tensor([[    0.0000,  -518.1846, -5440.3491, -7816.6743, -6283.8257]]),\n",
       " tensor([[-65081.5234, -52207.5742,      0.0000, -48023.3438, -16285.1172]]),\n",
       " tensor([[-6139489.5000, -5739018.5000, -7990084.0000, -2613495.2500,\n",
       "                 0.0000]]),\n",
       " tensor([[ -19956.7969, -106173.1250,  -86660.4297, -235472.8750,       0.0000]]),\n",
       " tensor([[-19683.5039, -99446.8125,  -2824.3667,      0.0000, -66736.4219]]),\n",
       " tensor([[-3534403.7500,  -276386.1250, -3746667.0000, -4525581.0000,\n",
       "                 0.0000]]),\n",
       " tensor([[-8690102.0000,        0.0000, -9567034.0000, -6278841.0000,\n",
       "          -5060162.5000]]),\n",
       " tensor([[-5186.8809, -5368.4644,     0.0000, -7950.0444, -5055.3257]]),\n",
       " tensor([[ -71393.8125,  -16535.1250, -124922.2188,       0.0000,  -59164.0000]]),\n",
       " tensor([[ -31888.1289, -138626.7656, -102477.9531,       0.0000,  -14353.9453]]),\n",
       " tensor([[-2117.8647,     0.0000, -1379.3124, -2625.5764, -2218.0566]]),\n",
       " tensor([[-107189.3438, -242575.9688,       0.0000, -151639.2656, -167475.3281]]),\n",
       " tensor([[     0.0000, -26961.4922, -13691.8838, -22250.4727, -11472.4941]]),\n",
       " tensor([[ -71886.0625,  -40463.1562, -115775.2500, -131127.9219,       0.0000]]),\n",
       " tensor([[ -286604.5000,        0.0000, -4047832.5000, -2777416.7500,\n",
       "          -2263453.5000]]),\n",
       " tensor([[-113272.9609,       0.0000, -187021.3438,  -85728.5703, -134733.9688]]),\n",
       " tensor([[-163719.4688,  -71730.8047,  -76248.7188, -143592.3438,       0.0000]]),\n",
       " tensor([[ -35979.0234, -126137.5312,  -80098.7812,  -72926.1094,       0.0000]]),\n",
       " tensor([[-458524.5625,       0.0000, -514336.0625, -248064.2500, -387701.9688]]),\n",
       " tensor([[ -38775.4961,       0.0000, -106402.2969,  -98552.7969,  -94108.7656]]),\n",
       " tensor([[-5229.1543,     0.0000, -1110.2576, -3759.6885, -1061.5546]]),\n",
       " tensor([[ -9728.2812,  -7865.3145,      0.0000, -48290.2812,  -5600.9844]]),\n",
       " tensor([[-156352.4688,  -96100.6406,  -84009.4453,       0.0000, -120561.6406]]),\n",
       " tensor([[      0.0000, -170194.7500,  -66864.5938, -129917.7500,   -4414.4033]]),\n",
       " tensor([[-5850353.5000,        0.0000, -6456153.0000, -3158937.5000,\n",
       "          -7439163.0000]]),\n",
       " tensor([[-323881.0938,  -83140.9688, -173668.0312,       0.0000, -209963.8750]]),\n",
       " tensor([[ -841.0200, -2733.3235,     0.0000, -2443.3992, -1633.6438]]),\n",
       " tensor([[-157154.1875,       0.0000, -158927.9062, -131523.0625,  -56417.0859]]),\n",
       " tensor([[ -6163.8779,  -6394.8076, -24205.9570, -78561.8125,      0.0000]]),\n",
       " tensor([[-157424.0938,       0.0000,  -58989.2266,  -49202.1367, -179964.0781]]),\n",
       " tensor([[      0.0000,  -35099.1406, -143047.5469,  -13919.9922,  -12124.9316]]),\n",
       " tensor([[      0.0000, -170509.9375, -121066.2656, -164523.3125, -183370.6562]]),\n",
       " tensor([[-196927.9844,  -39439.4102,  -42137.6914,       0.0000, -147589.5312]]),\n",
       " tensor([[-29390.3047,      0.0000, -64875.3906, -53626.8086, -51152.1367]]),\n",
       " tensor([[-231835.3594,       0.0000,  -29737.7227,  -96528.2969,  -56801.4766]]),\n",
       " tensor([[-49223.5977,  -1365.7500,      0.0000, -25207.8809, -12737.5498]]),\n",
       " tensor([[-26311.7812, -44692.1445, -85640.7891,      0.0000, -60315.3477]]),\n",
       " tensor([[-2268646.2500, -2309932.0000, -1865380.8750, -1431297.6250,\n",
       "                 0.0000]]),\n",
       " tensor([[ -1995.4868,      0.0000, -14504.8184, -28253.6738, -29532.6992]]),\n",
       " tensor([[-9748816.0000, -5257224.0000,        0.0000,  -929174.0000,\n",
       "          -3753469.7500]]),\n",
       " tensor([[-2702845.7500, -4727809.0000,        0.0000, -2374210.0000,\n",
       "          -3484427.0000]]),\n",
       " tensor([[ -55925.7109,       0.0000, -113515.1484,  -24637.8008,  -67093.9297]]),\n",
       " tensor([[-6184.6099,  -544.4762,     0.0000, -3984.1094,  -748.5639]]),\n",
       " tensor([[-71746.7656,      0.0000, -85850.4844, -85836.1562, -44180.4258]]),\n",
       " tensor([[-106316.1406,  -46093.3438,  -44398.7734, -105233.1094,       0.0000]]),\n",
       " tensor([[-3088538.0000, -4969221.0000,        0.0000,  -518527.5312,\n",
       "          -2300291.5000]]),\n",
       " tensor([[       0.0000, -8446849.0000,  -630769.5000, -3053248.0000,\n",
       "          -2016349.6250]]),\n",
       " tensor([[-186492.1250,       0.0000, -152192.3594, -207406.5625, -119664.2266]]),\n",
       " tensor([[ -77684.8359,       0.0000,  -53729.6875,  -76225.2969, -152871.6719]]),\n",
       " tensor([[      0.0000, -160338.5000, -111278.6406,  -98292.6484,  -75038.2031]]),\n",
       " tensor([[       0.0000,  -334551.4375, -4933349.0000, -1092041.6250,\n",
       "          -4033356.2500]]),\n",
       " tensor([[-299084.7188, -545631.1250, -560912.8750,       0.0000, -613608.1250]]),\n",
       " tensor([[-11453.4238, -33135.4883, -22202.3457,      0.0000, -16494.3457]]),\n",
       " tensor([[       0.0000, -3298094.0000, -4030050.0000, -2468371.0000,\n",
       "          -2768172.5000]]),\n",
       " tensor([[-5395.0713,     0.0000, -6046.6035, -5500.6650, -4338.0576]]),\n",
       " tensor([[    0.0000, -6331.3794, -2492.9941, -3369.8438, -4948.8423]]),\n",
       " tensor([[-1132771.7500, -3361561.2500,        0.0000, -7957432.0000,\n",
       "          -7816353.0000]]),\n",
       " tensor([[-1.7177e+05, -2.7691e+05, -1.4361e+02,  0.0000e+00, -2.8393e+05]]),\n",
       " tensor([[       0.0000, -4553917.0000, -4635549.5000, -5689882.0000,\n",
       "          -4077662.5000]]),\n",
       " tensor([[ -4340601.5000,   -448329.3750, -11687771.0000,         0.0000,\n",
       "           -4380885.0000]]),\n",
       " tensor([[      0.0000, -223623.8750, -236451.5156,  -46940.9375, -270593.2500]]),\n",
       " tensor([[ -448356.2500, -1267447.0000,        0.0000,  -777567.1250,\n",
       "           -420037.6562]]),\n",
       " tensor([[     0.0000, -71201.8594, -86229.7500, -71822.5859, -84678.3828]]),\n",
       " tensor([[-34122.6562, -26951.9316, -11194.8838,      0.0000, -22028.7070]]),\n",
       " tensor([[-143924.9375,       0.0000, -158300.6875, -154267.0312,  -46301.5078]]),\n",
       " tensor([[-260409.7188,  -48742.6562, -147554.4219, -143796.2969,       0.0000]]),\n",
       " tensor([[-1.0392e+08, -7.8009e+07, -1.8149e+07,  0.0000e+00, -7.6428e+07]]),\n",
       " tensor([[-1351.0911, -4751.9829, -4161.2803, -4550.9043,     0.0000]]),\n",
       " tensor([[-5876.6797,     0.0000, -1955.9248, -3636.6716,  -925.3885]]),\n",
       " tensor([[ -2977.7661,  -8329.8594,  -7402.6055,      0.0000, -11277.5312]]),\n",
       " tensor([[-8413.4658,     0.0000, -5451.8423, -5500.5576, -5275.4399]]),\n",
       " tensor([[-3581.9800,     0.0000,  -229.8142, -2315.5945,  -537.7535]]),\n",
       " tensor([[-142709.9844,  -92786.0781,   -6519.7383,       0.0000, -261517.4531]]),\n",
       " tensor([[-5147004.5000, -1365738.3750,        0.0000, -4543551.0000,\n",
       "          -1491007.2500]]),\n",
       " tensor([[-7370.0225,     0.0000, -3964.7422, -7730.9092, -3798.2847]]),\n",
       " tensor([[-248327.7188, -246545.4688,       0.0000, -153153.5156, -252363.6875]]),\n",
       " tensor([[     0.0000, -71940.2344, -77081.4844, -62273.3203, -60155.3516]]),\n",
       " tensor([[-5717657.5000,        0.0000, -7930176.0000, -7500332.5000,\n",
       "          -5896276.5000]]),\n",
       " tensor([[-152217.2188, -157303.8750, -148015.9531, -114531.1172,       0.0000]]),\n",
       " tensor([[-3849236.5000, -1195235.5000, -6299952.0000, -9248358.0000,\n",
       "                 0.0000]]),\n",
       " tensor([[ -92998.4922, -251975.5000,       0.0000,   -5081.8438,  -82881.3594]]),\n",
       " tensor([[-49234.2969, -91259.8203,      0.0000, -88538.6875, -40020.0156]]),\n",
       " tensor([[ -44415.2148,  -56509.7539,       0.0000,  -41355.4375, -156679.7500]]),\n",
       " tensor([[      0.0000,  -28477.0000, -131255.8125, -172836.2188,  -64213.2266]]),\n",
       " tensor([[      0.0000,  -40955.2969,   -8002.3594, -204851.8281, -233347.3750]]),\n",
       " tensor([[ -774.1322, -3438.4985,     0.0000, -1626.8921, -4592.9165]]),\n",
       " tensor([[ -411.9360, -6980.3184, -9529.8359,     0.0000, -5878.3765]]),\n",
       " tensor([[-20109.8203, -88895.3359,      0.0000, -87086.9609, -66637.1172]]),\n",
       " tensor([[-15898.9912, -14263.9434,      0.0000, -53883.3828,  -6785.7637]]),\n",
       " tensor([[-44869.3438,  -8125.4688, -22823.2207,  -3249.3789,      0.0000]]),\n",
       " tensor([[ -6493.5381, -53323.0312,      0.0000, -11511.1670, -17410.6152]]),\n",
       " tensor([[ -16641.2500,    -954.6309, -126516.7812,       0.0000,  -32319.2070]]),\n",
       " tensor([[-21218.7559,      0.0000, -26879.1074, -22587.7129, -24871.5508]]),\n",
       " tensor([[-105526.1562,       0.0000,  -68371.8750,  -90879.2812,  -70770.7109]]),\n",
       " tensor([[-300281.8750, -220012.0625, -221435.9844,       0.0000, -162287.6562]]),\n",
       " tensor([[-2005063.2500,  -525250.3125,        0.0000, -2160955.0000,\n",
       "           -330033.0000]]),\n",
       " tensor([[     0.0000, -21801.5977, -23348.9609, -34495.1562, -25397.5234]]),\n",
       " tensor([[-1454727.5000, -2836606.2500, -1085049.7500, -3007147.5000,\n",
       "                 0.0000]]),\n",
       " tensor([[ -16663.0156,       0.0000, -124474.0469, -100507.3594,  -30758.9570]]),\n",
       " tensor([[ -13646.3516, -117138.4844, -141980.1562,       0.0000, -138429.8750]]),\n",
       " tensor([[ -124780.5312, -1082983.3750, -1649017.8750,        0.0000,\n",
       "            -49693.5039]]),\n",
       " tensor([[-1021053.2500,        0.0000, -2593848.2500, -1741548.1250,\n",
       "           -847215.1250]]),\n",
       " tensor([[-2753386.0000, -1317345.0000, -1046036.1250,        0.0000,\n",
       "          -4327822.5000]]),\n",
       " tensor([[-4854508.5000, -4139792.7500,        0.0000, -2832945.7500,\n",
       "          -1983733.7500]]),\n",
       " tensor([[-1610.1512, -4285.9326,     0.0000, -2371.0786, -3483.3955]]),\n",
       " tensor([[-7738013.0000,        0.0000, -2586643.5000, -7676854.5000,\n",
       "          -4166719.0000]]),\n",
       " tensor([[-123396.9531,  -32981.4883,  -92421.7969, -122551.9688,       0.0000]]),\n",
       " tensor([[-138842.9062,   -6476.6514,       0.0000,  -62578.7305, -197674.7656]]),\n",
       " tensor([[      0.0000, -161758.7188, -112180.3281,  -17657.2812, -103913.7969]]),\n",
       " tensor([[    0.0000, -7120.6631, -9133.2207, -6269.9385, -6057.2505]]),\n",
       " tensor([[ -32185.2148, -129289.2344,  -14143.9062,  -65616.3984,       0.0000]]),\n",
       " tensor([[-2072.3328,  -786.1021,     0.0000,  -229.8970, -1096.9779]]),\n",
       " tensor([[-1449.7363, -4131.8364,     0.0000, -3246.5823, -1395.8362]]),\n",
       " tensor([[-114128.1719,  -53540.2812,  -41924.5469,       0.0000, -179183.3438]]),\n",
       " tensor([[-246017.0938,       0.0000, -171607.8438, -143970.4844, -107279.2344]]),\n",
       " tensor([[-12980.7539, -40860.1953,      0.0000, -79824.9297, -16743.9219]]),\n",
       " tensor([[-1929625.5000,        0.0000,  -709963.3125, -1939419.2500,\n",
       "          -1740650.3750]]),\n",
       " tensor([[-114192.1328,       0.0000, -209243.5469, -316856.1562, -225715.3750]]),\n",
       " tensor([[-7807219.0000, -3492063.2500,        0.0000, -5870512.0000,\n",
       "          -3988316.2500]]),\n",
       " tensor([[ -76314.0781,       0.0000, -116821.6250, -122100.8438,  -13874.7266]]),\n",
       " tensor([[ -5210.3594,  -9400.3457,      0.0000,  -4558.4404, -14829.6934]]),\n",
       " tensor([[ -38442.3320, -102232.4844,  -58191.0898,       0.0000, -112195.8750]]),\n",
       " tensor([[-277225.9375, -229680.3750,       0.0000, -273520.0938,  -71906.6094]]),\n",
       " tensor([[-138915.7969, -127783.7344,  -15331.0938,       0.0000,  -90848.8828]]),\n",
       " tensor([[ -85200.0469,       0.0000,  -39751.9023, -104048.8359,  -75454.4688]]),\n",
       " tensor([[      0.0000, -111658.3750, -124847.9062,  -84475.0156, -171523.3125]]),\n",
       " tensor([[-118604.7266,       0.0000, -140413.3438, -127300.2656,  -65574.9766]]),\n",
       " tensor([[-3139.5063,     0.0000, -1967.8444, -3612.0376, -3767.7993]]),\n",
       " tensor([[-1109.0094, -2917.8486, -4610.9087, -1931.6598,     0.0000]]),\n",
       " tensor([[-1678.5195,  -620.9484,     0.0000, -3614.5327, -3429.5195]]),\n",
       " tensor([[ -94347.0859, -152515.5469,       0.0000,  -36470.4375, -192785.4531]]),\n",
       " tensor([[        0.0000,  -6951680.5000, -12693754.0000,  -7793550.5000,\n",
       "           -7846701.5000]]),\n",
       " tensor([[-29154.4160,      0.0000,  -2896.2148, -39859.7188,  -5611.2319]]),\n",
       " tensor([[-17107.1543,  -2245.7549, -71029.0547,      0.0000, -15501.4316]]),\n",
       " tensor([[-249224.6562,       0.0000, -293452.4375, -160801.3750, -252426.1250]]),\n",
       " tensor([[-27671.9668,      0.0000, -85341.9062, -16230.7061, -32457.2930]]),\n",
       " tensor([[-39360.9062, -37623.6953, -67529.0156, -79882.2344,      0.0000]]),\n",
       " tensor([[-3587.8201, -3503.6475, -2650.1458, -1838.9504,     0.0000]]),\n",
       " tensor([[-7295025.,        0., -5221754., -3456419., -1217911.]]),\n",
       " tensor([[-2450.6533, -4975.4746,     0.0000, -5331.9043, -5575.8774]]),\n",
       " tensor([[-5605.2334, -5005.4844, -8310.0859, -3111.9058,     0.0000]]),\n",
       " tensor([[ -192.0795,     0.0000,  -226.4836,   -45.0217, -3272.4592]]),\n",
       " tensor([[ -61414.7422,       0.0000, -169262.1875,  -59730.5234,  -53566.1328]]),\n",
       " tensor([[ -20197.1562,  -92729.0781,  -89468.2891,       0.0000, -140691.5000]]),\n",
       " tensor([[-3183.8540, -4467.7676, -1454.5446, -3109.5215,     0.0000]]),\n",
       " tensor([[-170510.5625,  -94912.3359, -261138.6094, -138489.4219,       0.0000]]),\n",
       " tensor([[-1731435.5000, -3139316.2500, -2960835.0000, -4155002.7500,\n",
       "                 0.0000]]),\n",
       " tensor([[ -6159784.5000,  -2444521.0000,  -6007998.0000,         0.0000,\n",
       "          -13231720.0000]]),\n",
       " tensor([[-239120.5625, -156359.0000,       0.0000, -262112.3125, -247616.9688]]),\n",
       " tensor([[-1801.4119, -1849.2972,     0.0000, -2365.1953,  -110.5745]]),\n",
       " tensor([[-194986.6250,       0.0000, -143948.8438, -213316.9688, -161507.4062]]),\n",
       " tensor([[-85040.1172, -18109.1680, -80416.1562, -52962.4414,      0.0000]]),\n",
       " tensor([[ -69818.7266,  -68560.1641, -144250.8750,       0.0000,  -29180.7305]]),\n",
       " tensor([[ -51475.8281,       0.0000,  -23615.1406, -165370.3438, -272945.9062]]),\n",
       " tensor([[-88837.2109, -96708.7188, -23141.7461, -12335.4609,      0.0000]]),\n",
       " tensor([[      0.0000,  -65649.8672,  -65664.9766,  -12439.0586, -167572.6719]]),\n",
       " tensor([[-2350066.0000, -3075421.0000, -3026009.2500,        0.0000,\n",
       "          -1399094.6250]]),\n",
       " tensor([[    0.0000, -2844.0674, -1530.1884, -5585.4111, -3464.5088]]),\n",
       " tensor([[-1327.7117, -4207.0195,     0.0000, -1308.8038, -4808.2842]]),\n",
       " tensor([[-9862.4834,     0.0000, -8201.1719, -2581.3091, -3541.4509]]),\n",
       " tensor([[  -6528.2188,  -21788.0410,  -97487.8516,       0.0000, -104549.8906]]),\n",
       " tensor([[-199638.0312, -209060.4062, -144502.6094,  -67318.6719,       0.0000]]),\n",
       " tensor([[-130316.1016,       0.0000,  -65179.3789,  -94937.0938, -109990.6953]]),\n",
       " tensor([[-84689.0859, -49474.6094, -70825.4922,      0.0000, -29249.7754]]),\n",
       " tensor([[      0.0000, -129508.6719, -113385.1562, -111046.0625,  -81974.7109]]),\n",
       " tensor([[      0.0000, -140484.4062, -133665.2500,  -38193.5938,  -16077.2852]]),\n",
       " tensor([[-3662.7529,     0.0000,  -326.3401, -3489.4375, -5023.4771]]),\n",
       " tensor([[ -28951.9922,       0.0000, -175401.9688, -126963.2812, -126454.5078]]),\n",
       " tensor([[ -40325.5703, -106000.9375,  -51323.7930,       0.0000,  -57859.5352]]),\n",
       " tensor([[-4644.3213,     0.0000, -4384.8628, -5324.7637, -3676.2085]]),\n",
       " tensor([[-396291.5938,       0.0000, -529089.0000, -264123.3438, -280134.5312]]),\n",
       " tensor([[ -84621.6562,  -58705.1836, -303016.2812,   -1951.2720,       0.0000]]),\n",
       " tensor([[      0.0000,  -50286.1055,  -76239.1562, -204424.0938, -167352.2188]]),\n",
       " tensor([[-2958005.0000, -2214022.7500, -6569021.5000, -5957066.0000,\n",
       "                 0.0000]]),\n",
       " tensor([[ -5770.5205,      0.0000, -11858.2676,  -5654.7793,  -9404.2402]]),\n",
       " tensor([[-24288.2500,      0.0000, -22548.4219, -69189.8594, -31093.9688]]),\n",
       " tensor([[-273219.7500, -419180.3125,       0.0000, -440518.0625, -323568.4062]]),\n",
       " tensor([[-1388.1591,   -72.7371,  -301.0503, -1975.0631,     0.0000]]),\n",
       " tensor([[ -86358.5781, -151670.4531,  -49978.6523,  -15201.0391,       0.0000]]),\n",
       " tensor([[-107515.6875, -231476.4844, -103246.7812, -345995.2188,       0.0000]]),\n",
       " tensor([[-31449.8086,  -2572.0488, -43445.1211,      0.0000, -29704.2852]]),\n",
       " tensor([[-1677018.6250, -2188150.2500, -2410963.7500,  -165162.2500,\n",
       "                 0.0000]]),\n",
       " tensor([[-177225.0938,       0.0000, -122744.3750, -123886.3125, -177229.0000]]),\n",
       " tensor([[-120862.8125, -122439.9375,  -51359.2969,   -5836.8164,       0.0000]]),\n",
       " tensor([[-47797.9453, -72127.4531, -48133.9336, -23852.1699,      0.0000]]),\n",
       " tensor([[ -75264.2344,  -76328.1250,       0.0000, -111387.6250,  -15664.7656]]),\n",
       " tensor([[-51100.4336,      0.0000, -15193.8047, -17831.9316, -69405.6094]]),\n",
       " tensor([[ -87319.6172,  -33734.9805,       0.0000,  -52395.4688, -152394.5625]]),\n",
       " tensor([[-166089.4688, -169168.0625, -136940.8438,       0.0000, -121867.3906]]),\n",
       " tensor([[      0.0000,  -96965.9922, -272661.2188,  -33913.7578, -176194.9844]]),\n",
       " tensor([[-30915.4336, -18659.8242,      0.0000, -64239.8125, -66364.7500]]),\n",
       " tensor([[-2254386.5000,        0.0000, -4483123.0000, -9539011.0000,\n",
       "          -4538301.5000]]),\n",
       " tensor([[ -356.7002,  -608.2094,  -753.1947,     0.0000, -1808.7485]]),\n",
       " tensor([[-18391.1875,      0.0000, -12935.1543,  -6352.2427, -10748.2734]]),\n",
       " tensor([[ -1655.5635, -22060.2188, -43954.5625,      0.0000, -15796.7959]]),\n",
       " tensor([[-126652.1562,       0.0000, -102371.0625,  -92351.8594, -123140.0000]]),\n",
       " tensor([[-11878487.,  -4150796.,         0.,  -6892765., -11348014.]]),\n",
       " tensor([[-168705.8281,  -51371.9219,       0.0000,  -51716.3164,  -33979.3164]]),\n",
       " tensor([[-102524.9688,  -97779.6406,       0.0000, -126589.4688,  -40112.4141]]),\n",
       " tensor([[-10104.5342, -17429.0469, -15201.0488, -20948.2852,      0.0000]]),\n",
       " tensor([[-3042553.5000, -5708720.0000,        0.0000, -2903518.0000,\n",
       "          -4223119.5000]]),\n",
       " tensor([[ -77425.2578,  -76551.1719, -170556.8594, -211078.3125,       0.0000]]),\n",
       " tensor([[    0.0000, -4214.0488, -7079.0068, -4027.1956, -2143.2021]]),\n",
       " tensor([[-15125.2109, -35585.3281, -56343.2969, -47100.3750,      0.0000]]),\n",
       " tensor([[ -63287.4062,       0.0000,  -51824.9766,  -96302.8906, -211276.2500]]),\n",
       " tensor([[-247645.4219, -262574.2812,       0.0000, -194859.6250, -204237.0938]]),\n",
       " tensor([[-19745488., -19186894.,         0., -20756466.,  -8962687.]]),\n",
       " tensor([[-221614.9062, -176341.3125,       0.0000, -161503.5781, -134352.0469]]),\n",
       " tensor([[       0.0000, -2408911.0000, -6700952.5000, -4711375.5000,\n",
       "          -5970511.0000]]),\n",
       " tensor([[ -4003028.7500,         0.0000,    -88119.1875, -14665566.0000,\n",
       "           -5860103.0000]]),\n",
       " tensor([[-144022.0938,       0.0000, -275966.1562, -153638.6094,  -53379.5156]]),\n",
       " tensor([[  -8148.9375, -644201.7500,       0.0000, -954031.5000, -304900.3125]]),\n",
       " tensor([[ -13649.3438, -175814.2969,       0.0000, -151823.1406, -212775.7812]]),\n",
       " tensor([[     0.0000, -68226.5625, -18000.9297, -10913.5781, -55684.4922]]),\n",
       " tensor([[-109503.5156,  -57355.0117,  -60710.2891,  -30774.2852,       0.0000]]),\n",
       " tensor([[ -60986.8867, -105017.1953,  -70028.8281,  -64849.5156,       0.0000]]),\n",
       " tensor([[ -43450.8438, -179099.6406,       0.0000, -113495.3359,   -8851.7969]]),\n",
       " tensor([[-3375.3796, -2526.2769, -4491.0991, -5321.0273,     0.0000]]),\n",
       " tensor([[       0.0000, -2345566.0000,   -19123.8750,  -962468.7500,\n",
       "          -1033185.5000]]),\n",
       " tensor([[ -2605.6777, -24054.9297, -26997.9258,      0.0000, -27647.6719]]),\n",
       " tensor([[ -58535.2578,  -45736.0938,       0.0000, -127590.1562, -116124.7188]]),\n",
       " tensor([[-5391542.5000,        0.0000, -2985268.0000,  -721575.0625,\n",
       "          -1588268.2500]]),\n",
       " tensor([[ -91243.5781,       0.0000, -102132.0625,  -62690.0469, -102088.6562]]),\n",
       " tensor([[-4366.0000,     0.0000, -1039.9943, -3009.5176, -4655.3252]]),\n",
       " tensor([[ -7132.2637, -33688.9375, -67081.4688,      0.0000, -89770.2969]]),\n",
       " tensor([[-4292.9312, -3529.2200,     0.0000, -1329.7468, -3645.0344]]),\n",
       " tensor([[-67143.9453,      0.0000, -20641.2422,   -618.7617, -26869.8477]]),\n",
       " tensor([[-1583.1830, -1034.5232,     0.0000, -1000.9805, -2874.6736]]),\n",
       " tensor([[-59647.1445, -75395.1406, -27773.2012,      0.0000, -56291.4023]]),\n",
       " tensor([[ -65438.8711,  -10896.2656, -124665.6875,       0.0000,  -90653.6719]]),\n",
       " tensor([[  -486.8984, -77506.5312, -74274.5312,      0.0000, -99031.4453]]),\n",
       " tensor([[      0.0000,  -32971.1875,  -14234.1992, -100617.6328,  -57855.6250]]),\n",
       " tensor([[ -6676.7305,  -5624.3477, -24135.8281, -61832.2812,      0.0000]]),\n",
       " tensor([[ -65627.7188,  -15255.8516, -126834.3906,       0.0000, -195873.0312]]),\n",
       " tensor([[-1187596.5000, -2550515.5000, -5971255.0000,        0.0000,\n",
       "          -6160140.5000]]),\n",
       " tensor([[-3066541.7500, -2449788.5000, -2968908.5000, -2513849.5000,\n",
       "                 0.0000]]),\n",
       " tensor([[-119433.4062, -149684.3906, -180289.0938, -381856.4688,       0.0000]]),\n",
       " tensor([[-303322.8750, -536523.5000,       0.0000,  -72268.3125, -700417.1250]]),\n",
       " tensor([[    0.0000, -1871.6198, -1346.3588, -2116.6079, -3739.5911]]),\n",
       " tensor([[-116404.2969,       0.0000, -226632.9062, -280584.7500, -290211.3750]]),\n",
       " tensor([[-159225.2188, -189109.8125,  -21805.8203,       0.0000, -136344.5312]]),\n",
       " tensor([[-328374.9375, -590231.8750, -721581.7500, -567667.9375,       0.0000]]),\n",
       " tensor([[-139194.3438,  -61787.8086,       0.0000,  -59098.6250,  -78441.7031]]),\n",
       " tensor([[      0.0000, -362103.6875, -361950.0625, -296976.5000, -235722.8750]]),\n",
       " tensor([[    0.0000, -4514.2832, -5162.1055,  -301.5583, -2235.8813]]),\n",
       " tensor([[-4766330.0000, -3380439.7500,        0.0000, -2899908.7500,\n",
       "          -5294214.5000]]),\n",
       " tensor([[-26892.8281, -59016.6641, -56967.6406, -65979.3828,      0.0000]]),\n",
       " tensor([[ -799.3789, -2677.4702,     0.0000,  -156.8912,  -724.4898]]),\n",
       " tensor([[      0.0000,  -97167.1172, -150294.6719,  -27833.7188, -190693.0625]]),\n",
       " tensor([[-5980.9043,  -189.2855, -1526.6746,     0.0000, -2515.9290]]),\n",
       " tensor([[-249533.3906,       0.0000, -127724.2891, -339528.8125, -285707.4062]]),\n",
       " tensor([[-467615.9375,       0.0000,   -6513.1719,  -33783.9531, -196132.7969]]),\n",
       " tensor([[    0.0000, -3228.6973,  -482.0731, -4546.3613, -4575.8247]]),\n",
       " tensor([[ -77399.6719, -163036.2344, -215756.0000, -171464.9688,       0.0000]]),\n",
       " tensor([[      0.0000, -141824.6719, -107682.5625,  -33723.1875,  -91866.7656]]),\n",
       " tensor([[-5105688.5000, -6554443.0000, -3662605.2500,        0.0000,\n",
       "          -3587808.2500]]),\n",
       " tensor([[-86970.9922, -36266.0898, -89476.7969,  -1448.7344,      0.0000]]),\n",
       " tensor([[     0.0000, -55150.2031, -78541.6016, -28581.4453, -86835.4844]]),\n",
       " tensor([[-119780.4062, -175012.2188,       0.0000,  -34271.1406, -187308.0625]]),\n",
       " tensor([[-62500.5547,      0.0000, -39410.4883, -58243.8516, -58977.5234]]),\n",
       " tensor([[-2514.8306, -9374.7764,  -154.5161, -8318.9609,     0.0000]]),\n",
       " tensor([[-49678.2500, -15294.8164, -65486.1250,      0.0000, -76952.7188]]),\n",
       " tensor([[-107862.3828, -195001.1250,       0.0000, -281874.3750,  -85570.5625]]),\n",
       " tensor([[-1317156.8750,   -57298.0000,        0.0000, -3020352.7500,\n",
       "          -2515129.2500]]),\n",
       " tensor([[ -37909.9648, -132654.1875,       0.0000, -155344.4375, -106216.4141]]),\n",
       " tensor([[-1305182.0000,        0.0000,  -159026.0000, -3144940.5000,\n",
       "          -4096454.2500]]),\n",
       " tensor([[-2666.6265, -4454.8896, -2797.6035,     0.0000, -1531.8384]]),\n",
       " tensor([[ -6768.1973,  -6833.3911,      0.0000, -11219.6289,  -8030.8652]]),\n",
       " tensor([[-37395.0898, -35703.3984,      0.0000, -44394.9570, -16815.5898]]),\n",
       " tensor([[-47650.8203, -24528.6836, -64399.1406,      0.0000, -76022.6875]]),\n",
       " tensor([[ -80730.0938, -131374.5469,       0.0000,  -93675.9062,  -53340.3281]]),\n",
       " tensor([[ -71317.3125,       0.0000, -145108.0469,   -4792.3281, -171715.8750]]),\n",
       " tensor([[ -50742.4375,  -18075.4961,       0.0000, -152897.2188,  -23178.0273]]),\n",
       " tensor([[-501195.0625, -218788.0312,       0.0000, -270828.0000,  -56014.8438]]),\n",
       " tensor([[     0.0000,  -4007.4526, -21973.9922,  -9032.6123, -21778.3203]]),\n",
       " tensor([[    0.0000, -4609.7397, -1954.8943, -1968.9155, -7161.0342]]),\n",
       " tensor([[     0.0000, -44661.5078, -42217.8906,  -7516.6855,  -8860.3066]]),\n",
       " tensor([[-3686.5188, -4940.5010, -7049.1865,     0.0000,   -91.6016]]),\n",
       " tensor([[      0.0000, -190529.2500,  -17673.9766,  -84705.2031, -152967.8750]]),\n",
       " tensor([[    0.0000, -5627.6719, -6470.0869,  -721.6235, -3184.4924]]),\n",
       " tensor([[-260859.6250, -105200.2500, -134286.5156,       0.0000,  -90839.8750]]),\n",
       " tensor([[      0.0000, -123350.2969,  -65628.8906,  -17483.9453, -205299.8750]]),\n",
       " tensor([[-2219584.2500, -5326725.0000, -1192355.2500,        0.0000,\n",
       "          -4411197.0000]]),\n",
       " tensor([[ -83230.1719,       0.0000,  -69908.2344,  -76720.1562, -101260.6875]]),\n",
       " tensor([[-4441128.0000, -1731600.3750, -3360675.0000,        0.0000,\n",
       "          -2303303.0000]]),\n",
       " tensor([[ -78817.8438,  -95153.6797, -125672.1406,       0.0000, -139424.7031]]),\n",
       " tensor([[-7.0184e-02, -2.6915e+00, -1.0654e+03, -4.8832e+02, -2.3079e+02]]),\n",
       " tensor([[-8878577.0000, -7762162.5000, -6295196.0000, -3679053.7500,\n",
       "                 0.0000]]),\n",
       " tensor([[    0.0000, -4802.4624, -5176.5762, -1568.5935, -2374.8428]]),\n",
       " tensor([[-3242971.0000, -1431064.5000,        0.0000, -2308633.7500,\n",
       "          -1981689.6250]]),\n",
       " tensor([[       0.0000, -7650328.0000, -6286666.0000, -6354003.5000,\n",
       "          -3972057.0000]]),\n",
       " tensor([[ -156.0994,  -663.9161,  -922.9401,     0.0000, -3993.4614]]),\n",
       " tensor([[-4638528.0000, -1860030.5000, -5364673.0000, -4685132.5000,\n",
       "                 0.0000]]),\n",
       " tensor([[-1985945.5000, -1815153.2500, -3651408.5000, -4356602.0000,\n",
       "                 0.0000]]),\n",
       " tensor([[-15034.8047, -47328.8047, -28100.8984, -41446.5078,      0.0000]]),\n",
       " tensor([[      0.0000, -195223.4531, -233372.6250,  -34692.9531, -170026.5156]]),\n",
       " tensor([[  -8639.0234,  -92197.0859, -136059.1406,       0.0000,  -92029.6719]]),\n",
       " tensor([[-138815.9531, -192466.4531,  -88242.6094,       0.0000, -106754.6094]]),\n",
       " tensor([[-44318.6133,      0.0000, -64670.0781,  -3289.0938, -49263.1016]]),\n",
       " tensor([[ -9352377.0000, -11213410.0000,         0.0000,  -1424165.5000,\n",
       "           -9124827.0000]]),\n",
       " tensor([[ -8188.2607, -42288.8984,      0.0000, -54198.4062, -58083.3594]]),\n",
       " tensor([[      0.0000,  -63791.7500,  -88440.4219, -218752.8438, -217803.1562]]),\n",
       " tensor([[-89359.3750, -22443.7500, -36516.7695,      0.0000, -51074.2031]]),\n",
       " tensor([[      0.0000,  -19158.8320, -141069.5000,  -25114.1602,  -95748.2344]]),\n",
       " tensor([[-50119.4375, -21851.9395, -39966.1914, -45471.2461,      0.0000]]),\n",
       " tensor([[      0.0000,  -31453.3926, -106150.3047,  -41149.1953,  -62862.2383]]),\n",
       " tensor([[ -93127.9844, -215975.3438,       0.0000, -122104.7734,  -27368.8281]]),\n",
       " tensor([[-4719704.5000, -3286454.0000, -6296876.5000,        0.0000,\n",
       "          -6256682.0000]]),\n",
       " tensor([[ -71064.6094, -148720.8281,  -57917.5156,       0.0000,  -64223.3633]]),\n",
       " tensor([[-1544326.0000, -2821746.5000,  -728703.2500,        0.0000,\n",
       "          -1499345.2500]]),\n",
       " tensor([[       0.0000,  -185976.1250, -5399418.0000,  -308978.0000,\n",
       "          -2682762.0000]]),\n",
       " tensor([[ -197.4343, -2679.4087,   -76.8313,     0.0000, -2295.5850]]),\n",
       " tensor([[-55934.2578, -48607.2695, -92953.7031,      0.0000, -33577.8125]]),\n",
       " tensor([[-162539.3594,       0.0000, -241233.1250, -187119.6875, -157658.7031]]),\n",
       " tensor([[ -6721464.0000, -12871650.0000,         0.0000,  -4527549.0000,\n",
       "           -4361181.5000]]),\n",
       " tensor([[    0.0000, -7595.9121, -7985.6250, -2506.0493, -3061.4302]]),\n",
       " tensor([[-5192.3276, -6316.3467, -4187.6577,     0.0000, -5455.6172]]),\n",
       " tensor([[-2384059.2500,        0.0000, -3334083.0000, -3113534.7500,\n",
       "          -6244752.0000]]),\n",
       " tensor([[     0.0000,  -3527.0432, -19782.4863,  -2504.0249, -18374.8359]]),\n",
       " tensor([[-1264.2181, -3720.4160, -2929.0627,     0.0000, -1026.9180]]),\n",
       " tensor([[-18570.3750, -57851.1484,      0.0000, -95891.6094, -90849.7422]]),\n",
       " tensor([[-41988.0039,      0.0000, -58296.7773, -14949.3213,  -7770.3867]]),\n",
       " tensor([[-3475.9275, -5609.7119, -5228.7500, -2975.5640,     0.0000]]),\n",
       " tensor([[-480506.6250, -176843.5938, -342546.2500, -372744.4688,       0.0000]]),\n",
       " tensor([[-311237.2500, -201516.2188, -149443.2344,       0.0000, -262895.7500]]),\n",
       " tensor([[-83959.9766,      0.0000, -80020.9375, -31357.7090, -88659.0156]]),\n",
       " tensor([[ -83937.6641,  -20046.0508, -101642.6016,  -75023.3516,       0.0000]]),\n",
       " tensor([[      0.0000, -124578.1094, -100855.4609, -129410.6406,  -33790.6797]]),\n",
       " tensor([[ -836472.9375, -1117041.1250, -1445998.5000,        0.0000,\n",
       "           -293210.5625]]),\n",
       " tensor([[ -50832.8359,       0.0000, -112205.4219,  -53720.7852, -188445.6875]]),\n",
       " tensor([[ -75954.0391, -129768.4062,  -31729.2109,  -49245.1523,       0.0000]]),\n",
       " tensor([[       0.0000, -6710941.5000, -4465453.5000, -5500945.5000,\n",
       "          -7584033.0000]]),\n",
       " tensor([[-105459.8750,  -95709.2188,       0.0000,   -6618.3867, -141065.1250]]),\n",
       " tensor([[ -94629.0625, -124986.5312,       0.0000,  -84750.7344,  -88006.2344]]),\n",
       " tensor([[-121465.6484, -200662.4688, -139602.6250, -221681.8750,       0.0000]]),\n",
       " tensor([[-297411.9375, -195874.1875, -215407.6875,       0.0000, -221812.8438]]),\n",
       " tensor([[ -11580.9805,  -61525.1914, -143609.0156,  -13327.5801,       0.0000]]),\n",
       " tensor([[-24898.7402,  -5883.1055,      0.0000, -54288.2461, -29509.3711]]),\n",
       " tensor([[-179355.5938,       0.0000, -169639.7188,  -21142.4375, -334998.5312]]),\n",
       " tensor([[      0.0000, -363799.2188, -527283.7500, -491612.3125, -504548.4375]]),\n",
       " tensor([[-62053.5469, -81376.7109, -49371.4062,      0.0000,  -8382.3398]]),\n",
       " tensor([[ -55938.4531, -142359.7344,  -43597.5625,  -58299.1719,       0.0000]]),\n",
       " tensor([[-110396.2969,  -69746.8750,  -74312.1719,  -96835.3672,       0.0000]]),\n",
       " tensor([[-121212.1250, -123187.1094,  -20547.7656,       0.0000, -100890.4766]]),\n",
       " tensor([[ -437.7703, -4101.2646, -1126.7676,  -405.1995,     0.0000]]),\n",
       " tensor([[-19714.5254,      0.0000, -95492.9141, -12202.8086,  -9783.6719]]),\n",
       " tensor([[-85293.7031, -26732.1152,      0.0000, -70541.2656, -49968.4922]]),\n",
       " tensor([[-14487.7412,      0.0000,  -4139.3271,  -3733.6982,  -1967.1499]]),\n",
       " tensor([[-3096.3794, -1841.4072, -2002.0045,     0.0000,  -728.6309]]),\n",
       " tensor([[-1585.8738,     0.0000, -5339.8730, -4406.3213, -3696.7778]]),\n",
       " tensor([[ -13998.8125, -387177.2812, -114794.6797, -256304.9062,       0.0000]]),\n",
       " tensor([[-116157.6953,  -32599.6133,       0.0000,   -8599.5430,  -94625.2422]]),\n",
       " tensor([[-75102.6094, -40830.9297, -40554.9219, -55261.2344,      0.0000]]),\n",
       " tensor([[-84067.0156, -37737.9453, -11151.1504, -36682.2266,      0.0000]]),\n",
       " tensor([[-36001.0547,  -9195.0664, -40734.4531,      0.0000, -26688.2168]]),\n",
       " tensor([[-4056629.2500, -2288648.7500, -4334135.0000, -1437083.3750,\n",
       "                 0.0000]]),\n",
       " tensor([[-2360.8091, -5577.8730, -7954.4341, -4536.9585,     0.0000]]),\n",
       " tensor([[-223380.6406, -332551.8125,       0.0000, -175338.7188, -191663.1406]]),\n",
       " tensor([[  -9104.2188,  -22530.4336,  -93937.0703, -117712.5156,       0.0000]]),\n",
       " tensor([[-27193.2422, -12168.0947,      0.0000, -34207.3789, -41592.4922]]),\n",
       " tensor([[     0.0000, -58514.6484, -32950.6719,  -5513.7500, -11542.3008]]),\n",
       " tensor([[-23600.1973,      0.0000, -82980.1641, -70719.1250, -63490.3711]]),\n",
       " tensor([[-69950.3906,      0.0000, -32530.7227, -18692.3770, -26217.6973]]),\n",
       " tensor([[ -1623630.5000, -10183428.0000,  -5686982.0000,  -8790896.0000,\n",
       "                  0.0000]]),\n",
       " tensor([[-129051.9453,  -28342.4766, -116455.8438, -157529.5625,       0.0000]]),\n",
       " tensor([[ -6555717.0000,         0.0000,   -716260.5000, -12627184.0000,\n",
       "          -23101164.0000]]),\n",
       " tensor([[-21849268., -11495788.,         0.,  -7167131.,  -9402695.]]),\n",
       " tensor([[-5092.3813, -5433.3306,     0.0000, -4821.8633, -2556.6099]]),\n",
       " tensor([[ -79640.1016,  -94598.8750, -148456.5000,  -80711.8672,       0.0000]]),\n",
       " tensor([[ -92094.1719, -142465.1875,  -65453.1680,  -57866.6016,       0.0000]]),\n",
       " tensor([[-37534.0859, -28193.1914,      0.0000, -41416.6484, -24469.0918]]),\n",
       " tensor([[-1701097.7500,  -583035.0000, -2520022.2500, -4933392.0000,\n",
       "                 0.0000]]),\n",
       " tensor([[    0.0000,  -974.1096, -2249.8977, -2335.1294, -2068.8748]]),\n",
       " tensor([[       0.0000, -2895476.7500, -6499893.5000, -2537491.0000,\n",
       "          -1380389.6250]]),\n",
       " tensor([[-181420.4062,       0.0000, -141121.2031, -232326.9844, -263991.3750]]),\n",
       " tensor([[     0.0000, -21324.1582,  -1218.6531,  -9109.1055, -11999.7695]]),\n",
       " tensor([[ -44155.9141,       0.0000,  -79821.4844,  -44785.1562, -133206.7344]]),\n",
       " tensor([[       0.0000, -3828842.0000, -1030720.5625,   -27910.7500,\n",
       "          -4797563.0000]]),\n",
       " tensor([[-1375787.1250,        0.0000, -1578395.0000, -1198424.2500,\n",
       "           -931005.0000]]),\n",
       " tensor([[-127146.8359, -125954.0000,   -5917.6172,       0.0000,  -44504.1328]]),\n",
       " tensor([[    0.0000,  -255.4346, -2741.8669,  -504.2700, -3110.7085]]),\n",
       " tensor([[-79873.7500, -87209.4844, -51604.4609,      0.0000, -75783.1719]]),\n",
       " tensor([[-48193.8633, -19317.8359,      0.0000, -40347.4766, -96764.0625]]),\n",
       " tensor([[      0.0000,   -7909.9727,  -18214.7969, -101328.8594, -107258.4531]]),\n",
       " tensor([[  -2653.7969,  -26733.4297,       0.0000, -152041.2031,  -47670.4844]]),\n",
       " tensor([[ -5872.1748, -62481.7031, -19410.8203,      0.0000, -93075.1484]]),\n",
       " tensor([[-6383.4536, -6157.1470,     0.0000, -7358.9165, -9480.0684]]),\n",
       " tensor([[-2076.5503,     0.0000, -2563.2283, -4354.2974, -3918.9438]]),\n",
       " tensor([[-2391.4204, -4999.8613,  -594.3032,     0.0000, -8134.4043]]),\n",
       " tensor([[-185520.4375, -168005.7969, -195252.4688,       0.0000, -199759.7969]]),\n",
       " tensor([[ -45790.2461,       0.0000,  -58515.3125,  -24796.0879, -117816.0938]]),\n",
       " tensor([[-3651716.0000, -1312536.7500,        0.0000,  -206465.3750,\n",
       "            -13844.3125]]),\n",
       " tensor([[    0.0000, -5488.8203, -3161.7837, -7099.1416, -3375.8425]]),\n",
       " tensor([[-2036801.7500, -7979958.0000,  -652545.7500,  -963417.2500,\n",
       "                 0.0000]]),\n",
       " tensor([[ -50392.9922,  -15955.0352,  -60952.2773,       0.0000, -101205.4766]]),\n",
       " tensor([[ -3585.3867,      0.0000, -17114.2910, -21868.4961,  -3733.6709]]),\n",
       " tensor([[      0.0000,  -40416.6875, -170632.9219, -149317.4062,  -78165.7656]]),\n",
       " tensor([[-115790.2500,  -97971.7969, -105978.0156,       0.0000, -161807.2500]]),\n",
       " tensor([[-3059540.7500, -6720115.0000,        0.0000, -9244442.0000,\n",
       "          -4927020.0000]]),\n",
       " tensor([[        0., -11116662.,  -8843211.,  -9728244.,  -8526547.]]),\n",
       " tensor([[-3641538.5000, -2890641.0000,        0.0000, -6327324.0000,\n",
       "           -952014.0000]]),\n",
       " tensor([[ -910607.6250, -2536855.7500,        0.0000, -1140315.2500,\n",
       "           -989152.3750]]),\n",
       " tensor([[     0.0000, -24293.7324, -18137.8770, -19132.7305,  -6456.0298]]),\n",
       " tensor([[-103661.8594, -128787.0469,  -37707.4258,  -80059.5703,       0.0000]]),\n",
       " tensor([[       0.0000, -4529041.0000, -3994212.5000, -4813555.5000,\n",
       "          -2465179.0000]]),\n",
       " tensor([[      0.0000, -254665.4375, -100826.8984, -140173.1094, -126498.7578]]),\n",
       " tensor([[-213220.8750,       0.0000, -111386.2500, -183088.5312, -212250.3594]]),\n",
       " tensor([[-3201.2949,     0.0000, -1029.4749, -5050.5605, -2208.6589]]),\n",
       " tensor([[-4963.9727, -2472.8198, -2796.2947,     0.0000, -5608.1846]]),\n",
       " tensor([[-19445.3301, -34760.4453, -24295.3008,      0.0000,  -8361.4189]]),\n",
       " tensor([[ -81746.6406,       0.0000, -116180.9531, -114575.8750,  -85186.6406]]),\n",
       " tensor([[ -50476.8125,       0.0000, -198453.3906,  -26885.1387, -105846.8125]]),\n",
       " tensor([[-17525.5312,  -7806.1626,  -7665.1470,      0.0000,  -5910.2500]]),\n",
       " tensor([[-110397.7031,       0.0000,  -71558.0625,  -14743.4414,  -26366.3848]]),\n",
       " tensor([[-183700.4062, -170000.6719, -197993.0000,       0.0000,  -15848.0195]]),\n",
       " tensor([[      0.0000, -113472.0859, -166629.5469, -128909.3672,  -98431.8750]]),\n",
       " tensor([[-133474.4375,  -19006.7734, -123628.2891,       0.0000,  -61716.2031]]),\n",
       " tensor([[-45222.4922,      0.0000, -23948.4746, -30693.0859, -31624.9746]]),\n",
       " tensor([[ -36354.8828,  -14364.3359,  -95658.4609,       0.0000, -151712.4688]]),\n",
       " tensor([[-1398.0989, -2137.9021,  -192.3090,  -143.8037,     0.0000]]),\n",
       " tensor([[-201445.7188,       0.0000, -317990.9688, -220098.1250, -145602.1562]]),\n",
       " tensor([[-4809313.0000,        0.0000, -5562840.0000, -7362438.0000,\n",
       "           -813888.2500]]),\n",
       " tensor([[-120436.1484, -210985.0625,  -34900.4531, -109896.5547,       0.0000]]),\n",
       " tensor([[     0.0000, -71856.4844,  -2414.7188, -24857.8184, -74093.7188]]),\n",
       " tensor([[    0.0000, -4987.9312, -1468.0703, -7079.7114, -2313.8916]]),\n",
       " tensor([[      0.0000, -173673.4688,  -88765.8125,   -3499.1328,  -64687.2773]]),\n",
       " tensor([[ -97844.8359,  -50042.3203,       0.0000,   -8049.9453, -123807.6172]]),\n",
       " tensor([[ -90390.7031,  -76903.8594, -124077.2188,  -95456.7422,       0.0000]]),\n",
       " tensor([[      0.0000,    -791.4375,  -95154.6406, -288994.6250, -213405.9688]]),\n",
       " tensor([[-175842.1562,       0.0000,  -17120.7109,  -96440.3516, -140893.5781]]),\n",
       " tensor([[-22544.9414, -82194.4141,      0.0000, -25882.2031, -52733.7617]]),\n",
       " tensor([[-1257224.5000, -1417258.1250,  -374013.8750,  -543485.1250,\n",
       "                 0.0000]]),\n",
       " tensor([[-12455535.0000,  -6775764.5000,  -3379458.0000,         0.0000,\n",
       "          -14458404.0000]]),\n",
       " tensor([[-61297.2422, -26531.1074,      0.0000,   -816.5215, -82590.4688]]),\n",
       " tensor([[-1424728.0000, -8522694.0000,        0.0000, -8660365.0000,\n",
       "          -6674797.5000]]),\n",
       " tensor([[-90759.7734,      0.0000, -68402.0938, -47077.2617, -13209.7031]]),\n",
       " tensor([[-1267757.5000,        0.0000, -2340213.5000,  -523320.0625,\n",
       "           -713927.1250]]),\n",
       " tensor([[-7666966.0000,        0.0000, -4115785.2500, -2207413.5000,\n",
       "          -2781574.0000]]),\n",
       " tensor([[-114956.1641, -129567.4141,       0.0000,   -1320.8594,  -58319.3047]]),\n",
       " tensor([[ -770231.0000,        0.0000, -5938138.0000,  -157347.2500,\n",
       "          -1844366.6250]]),\n",
       " tensor([[ -649498.0000, -1791128.6250,   -55896.6250,  -508251.2500,\n",
       "                 0.0000]]),\n",
       " tensor([[-7211763.5000, -2296539.0000, -7793073.0000, -1623996.8750,\n",
       "                 0.0000]]),\n",
       " tensor([[        0.,  -1542767.,  -2972457.,  -7828518., -13460401.]]),\n",
       " tensor([[    0.0000, -1965.8358, -4047.8750, -1196.2731, -1222.6023]]),\n",
       " tensor([[-21210.6328, -85010.7812, -38749.6211,      0.0000, -31674.5566]]),\n",
       " tensor([[-1834396.5000, -2994890.0000, -1517319.2500,        0.0000,\n",
       "          -1651106.0000]]),\n",
       " tensor([[ -6275.1431, -10388.0225,  -4603.0269,  -3267.7510,      0.0000]]),\n",
       " tensor([[-2459.4343, -5853.8555, -6724.3721, -2198.9360,     0.0000]]),\n",
       " tensor([[-1411133.5000,  -521268.4375,  -505135.0938,        0.0000,\n",
       "            -91400.4062]]),\n",
       " tensor([[-122812.2734,       0.0000,  -47734.5156, -211002.0938, -181046.9375]]),\n",
       " tensor([[ -77805.0547, -120423.9375, -102547.2109,  -12899.5391,       0.0000]]),\n",
       " tensor([[ -74560.2031,  -50803.4570, -127435.4062,       0.0000, -117748.8281]]),\n",
       " tensor([[-2691882.5000, -2008645.1250, -4834763.0000,  -145040.5000,\n",
       "                 0.0000]]),\n",
       " tensor([[-37791.9141, -55958.3555,  -5112.7285, -16326.6250,      0.0000]]),\n",
       " tensor([[ -70674.8438,       0.0000, -178361.3125, -161965.2969,  -34059.4609]]),\n",
       " tensor([[ -86119.6562,       0.0000, -128114.1406, -308635.5312, -252981.9375]]),\n",
       " tensor([[ -677649.5625, -1406397.1250,  -696293.7500,  -996992.0625,\n",
       "                 0.0000]]),\n",
       " tensor([[-1351401.7500, -3178735.2500, -3225235.0000, -3121568.7500,\n",
       "                 0.0000]]),\n",
       " tensor([[ -912786.1875,  -588859.3750, -4283429.5000, -4227147.0000,\n",
       "                 0.0000]]),\n",
       " tensor([[-104226.7344,  -43942.2422,       0.0000,  -39628.1758,  -52461.9336]]),\n",
       " tensor([[-2757.9487, -1391.0264, -3619.5840,     0.0000, -2745.7720]]),\n",
       " tensor([[ -76341.4297,  -59458.8281, -100144.0156,  -32427.4199,       0.0000]]),\n",
       " tensor([[        0.0000,  -1636846.7500,  -7839243.0000,  -5530998.0000,\n",
       "          -10420822.0000]]),\n",
       " tensor([[     0.0000, -18204.6250, -34935.1836, -78323.3281, -62027.8398]]),\n",
       " tensor([[ -91522.0312,   -3933.9531, -500717.1250, -150777.8438,       0.0000]]),\n",
       " tensor([[    0.0000, -3781.4219, -8230.5693, -1874.9412, -4640.5005]]),\n",
       " tensor([[      0.0000,  -62810.8477,   -9110.9258, -120668.2109,  -96624.6719]]),\n",
       " tensor([[-2694042.5000, -1926146.7500,  -600641.6250,        0.0000,\n",
       "          -3848704.7500]]),\n",
       " tensor([[-183873.0312,       0.0000, -513900.7812, -346891.9375, -152417.7188]]),\n",
       " tensor([[      0.0000, -102835.3828,  -60220.8828,  -81588.1875, -117095.9844]]),\n",
       " tensor([[-14422.9336, -61584.2188,      0.0000, -64574.0938, -34623.2344]]),\n",
       " tensor([[ -97767.1406, -115668.3438,       0.0000, -327407.5000, -187944.5156]]),\n",
       " tensor([[-1507364.7500, -2539161.7500,  -696673.1250,        0.0000,\n",
       "          -5968662.0000]]),\n",
       " tensor([[ -84507.1328,  -72790.0000, -177462.0312, -103312.7109,       0.0000]]),\n",
       " tensor([[-4335305.5000, -2534399.2500,        0.0000,  -816121.3750,\n",
       "            -80484.0000]]),\n",
       " tensor([[-44035.2227,  -4606.8867, -57013.9492,      0.0000, -55287.0234]]),\n",
       " tensor([[ -127491.6875, -2980890.7500,        0.0000,  -416946.6562,\n",
       "           -991654.3125]]),\n",
       " tensor([[     0.0000,  -1539.7046,  -4796.3247, -12408.7510,  -4179.0122]]),\n",
       " tensor([[-4358.2227, -3675.3506, -3552.7139,     0.0000,  -379.5088]]),\n",
       " tensor([[ -48415.3359,       0.0000,  -61743.8906,  -99881.8438, -118355.2109]]),\n",
       " tensor([[-298952.6875,       0.0000, -113717.0078,  -10892.1406, -150437.7656]]),\n",
       " tensor([[-3191812.0000, -3480975.0000, -1029717.9375, -4411408.0000,\n",
       "                 0.0000]]),\n",
       " tensor([[ -41903.0977, -117217.4531,  -67580.2812,       0.0000, -149782.9688]]),\n",
       " tensor([[ -4007.6162, -13051.3223,  -8119.2119,      0.0000,  -3017.2603]]),\n",
       " tensor([[-16538.5078, -17085.4492, -11602.8848,      0.0000,  -2774.8704]]),\n",
       " tensor([[-149205.6250, -166210.5156, -363022.5000,       0.0000, -133168.9062]]),\n",
       " tensor([[ -624489.6250,  -467127.3750, -1126251.3750,        0.0000,\n",
       "          -1703766.0000]]),\n",
       " tensor([[-120083.5312,       0.0000, -138943.3594, -125636.6562, -169707.3750]]),\n",
       " tensor([[ -818.4509, -2042.6453, -9904.5479,  -217.0642,     0.0000]]),\n",
       " tensor([[-183857.5156, -189699.3594,  -12497.4570,  -19533.1875,       0.0000]]),\n",
       " tensor([[     0.0000, -92159.9844, -17925.9609, -64030.8750, -43245.3438]]),\n",
       " tensor([[-199703.4844, -327246.7500,       0.0000, -162776.4375, -195793.3438]]),\n",
       " tensor([[ -690347.9375,        0.0000, -1744533.8750, -1507630.8750,\n",
       "          -1860955.1250]]),\n",
       " tensor([[-28960.5234,      0.0000,  -8967.8281, -22149.1934, -54970.5469]]),\n",
       " tensor([[-335453.9062, -659331.3750,       0.0000, -357508.5312, -507616.4375]]),\n",
       " tensor([[-123035.9844,  -56431.9609,       0.0000,  -97644.1953,  -80946.3203]]),\n",
       " tensor([[       0.0000, -4604398.0000, -3614129.7500, -1242999.3750,\n",
       "          -1478779.7500]]),\n",
       " tensor([[-45353.0625, -56742.0938, -88264.3906, -39522.6602,      0.0000]]),\n",
       " tensor([[-213619.7188,       0.0000, -169128.4531, -218047.9375, -161682.0312]]),\n",
       " tensor([[     0.0000, -67146.1953, -48017.4805, -57707.6875, -35209.4297]]),\n",
       " tensor([[-24717.3555,      0.0000, -10038.2188,  -6485.4731, -18632.2480]]),\n",
       " tensor([[      0.0000, -216706.8125, -262333.8438, -202703.7969, -158255.0469]]),\n",
       " tensor([[      0.0000,  -94438.2734,  -75268.8516, -130040.2969, -103644.6562]]),\n",
       " tensor([[ -46765.1484, -151088.7812,  -74374.9219,       0.0000,  -42025.1328]]),\n",
       " tensor([[ -895.9096,     0.0000,  -964.2319, -1228.8246, -4687.1636]]),\n",
       " tensor([[  -9227.9668, -116364.6719,       0.0000,  -70069.9219,  -56173.2031]]),\n",
       " tensor([[-35148.1719, -58641.4062, -52601.4023, -34235.1953,      0.0000]]),\n",
       " tensor([[ -54023.4883, -188615.6719,       0.0000,  -88963.1875, -141127.1562]]),\n",
       " tensor([[-36006.1562, -64021.2812,      0.0000, -24044.0605, -68226.3906]]),\n",
       " tensor([[      0.0000,  -16036.1562, -818621.6250, -708002.3750,  -54214.5781]]),\n",
       " tensor([[-57928.4414, -71986.4688, -73864.5625, -43453.7422,      0.0000]]),\n",
       " tensor([[-9479526.0000, -1747823.3750, -4564005.0000,        0.0000,\n",
       "          -1338875.2500]]),\n",
       " tensor([[-150343.6719, -151149.2656, -124356.9062,  -87226.5000,       0.0000]]),\n",
       " tensor([[-3600930.7500, -4380339.0000, -3863764.0000,        0.0000,\n",
       "          -3688335.7500]]),\n",
       " tensor([[-73148.8984,      0.0000, -53303.6289, -61959.2305, -27502.6562]]),\n",
       " tensor([[-3616807.5000, -2748041.0000, -1505932.3750, -1303409.2500,\n",
       "                 0.0000]]),\n",
       " tensor([[-139528.0625,       0.0000,  -86601.3750, -109654.3750,  -39272.4648]]),\n",
       " tensor([[-1869.2241,  -331.3381, -3222.4053,     0.0000, -1604.1095]]),\n",
       " tensor([[-294208.6250, -325743.9375,       0.0000, -258686.3750, -348447.6875]]),\n",
       " tensor([[     0.0000,  -2337.8730, -49125.0234, -26991.8164, -27933.3184]]),\n",
       " tensor([[    0.0000, -1313.8226, -2908.2307, -3408.8369, -3860.4214]]),\n",
       " tensor([[-28396.8672,      0.0000, -16527.0098, -15630.5713, -21225.6953]]),\n",
       " tensor([[ -94560.9844, -161297.1875, -145964.6719,       0.0000, -121979.1875]]),\n",
       " tensor([[ -13722.1523,       0.0000,  -79264.2969,  -27948.6875, -171944.6406]]),\n",
       " tensor([[ -96000.3359,  -90116.6172,  -76532.3828, -108001.8125,       0.0000]]),\n",
       " tensor([[    0.0000, -4326.7344,   -67.4923, -3923.1494, -4243.9062]]),\n",
       " tensor([[-3756.1504, -3895.0186, -2777.3176,     0.0000, -1878.2374]]),\n",
       " tensor([[-219881.7812,   -1164.2891,       0.0000,  -83411.7422, -115139.0312]]),\n",
       " tensor([[-4324.7114, -1550.8684,  -435.4617, -6578.5034,     0.0000]]),\n",
       " tensor([[-44464.1797,      0.0000, -86937.9141, -40586.3594, -71641.8906]]),\n",
       " tensor([[       0.0000, -1065928.3750, -1734235.7500,  -438244.4375,\n",
       "          -1347137.2500]]),\n",
       " tensor([[-118929.7891, -117795.7578,  -62577.8633,       0.0000, -163317.1250]]),\n",
       " tensor([[-100197.7656,  -66132.5625,       0.0000, -246243.5156,  -67738.1172]]),\n",
       " tensor([[    0.0000, -4549.5947, -5785.9956, -2145.0085, -2694.9951]]),\n",
       " tensor([[-35788.1367, -72708.7969, -27907.0508,  -6778.1729,      0.0000]]),\n",
       " tensor([[-143260.0156,       0.0000,  -98428.5000, -105955.1875, -160224.2031]]),\n",
       " tensor([[-2575.3218,     0.0000, -3318.8777, -4109.5752, -5320.0049]]),\n",
       " tensor([[-2354.8994, -4876.7876, -1722.5388,     0.0000, -3986.1960]]),\n",
       " tensor([[-2178239.,        0.,  -856400., -2470476., -9430152.]]),\n",
       " tensor([[      0.0000, -475004.8125, -229828.6250, -473303.9062, -386508.0312]]),\n",
       " tensor([[ -363.3386,     0.0000, -4189.8633, -3956.6714, -4932.2905]]),\n",
       " tensor([[-47902.2656,      0.0000, -14904.4668,   -590.9648, -57730.8867]]),\n",
       " tensor([[      0.0000, -241093.7188, -184196.6250,  -79168.5547,  -19515.2578]]),\n",
       " tensor([[ -40248.7031,  -33534.9805, -149114.0938,       0.0000,  -37342.2148]]),\n",
       " tensor([[-10986812.0000,         0.0000,  -7908178.0000, -10049530.0000,\n",
       "           -7437480.5000]]),\n",
       " tensor([[-3686356.5000, -4301170.0000,  -799513.2500,        0.0000,\n",
       "          -2703289.5000]]),\n",
       " tensor([[-22654342., -11694425.,         0., -18815736., -10748183.]]),\n",
       " tensor([[-75657.0859, -72721.2578,      0.0000,   -747.1641, -22130.1445]]),\n",
       " tensor([[ -50610.6875,  -23736.5762,       0.0000,    -218.0586, -139165.0312]]),\n",
       " tensor([[      0.0000,  -17284.5625,  -71571.0781, -100234.8750, -117357.1094]]),\n",
       " tensor([[       0.0000, -2250239.5000,  -582632.5000,  -967466.6250,\n",
       "           -546120.7500]]),\n",
       " tensor([[-1247.7006,     0.0000, -7433.1553, -5047.6875, -2410.8384]]),\n",
       " tensor([[-112998.7188, -179435.0312, -135961.2031,       0.0000,  -92757.7969]]),\n",
       " tensor([[-65937.5156, -19174.1680, -74645.6172,      0.0000,  -5865.2773]]),\n",
       " tensor([[-155330.5156, -496300.5625,       0.0000, -164298.5938, -138656.9688]]),\n",
       " tensor([[-4040146., -7119445.,        0., -9721094., -7330693.]]),\n",
       " tensor([[-37555.8047, -30882.1934,      0.0000, -30637.0137, -26716.6289]]),\n",
       " tensor([[ -62641.1250, -109720.7188, -243033.5312,       0.0000,  -18745.0781]]),\n",
       " tensor([[ -57363.2461, -155578.6250,  -57102.6250, -184741.5312,       0.0000]]),\n",
       " tensor([[ -80188.0781,  -33515.7422,  -56126.1875,       0.0000, -121801.1172]]),\n",
       " tensor([[-4053749.2500, -6472693.0000,        0.0000, -3100510.5000,\n",
       "          -4129327.5000]]),\n",
       " tensor([[-35254.5625, -27352.7598, -31190.4316,  -6798.0508,      0.0000]]),\n",
       " tensor([[     0.0000, -83622.8672, -20783.3613, -33925.2188,  -5400.9263]]),\n",
       " tensor([[-104245.8906,  -62822.6797,  -68609.5469,  -27208.1992,       0.0000]]),\n",
       " tensor([[-2241.6970, -7608.5645, -6453.7842, -2553.5022,     0.0000]]),\n",
       " tensor([[-127398.5625, -135435.3750,       0.0000, -224828.3438, -323874.2812]]),\n",
       " tensor([[-232366.5938,       0.0000, -328546.8125, -278187.5000, -248759.1875]]),\n",
       " tensor([[      0.0000,  -44318.4766, -154732.4375,  -93075.5781, -172558.2188]]),\n",
       " tensor([[-229709.2188, -186469.3750,  -35067.1328,       0.0000, -291285.7188]]),\n",
       " tensor([[ -67088.9531, -192912.0000, -112532.5781,       0.0000, -225837.0781]]),\n",
       " tensor([[    0.0000, -3368.1523, -3024.2571, -2465.0022, -2249.7517]]),\n",
       " tensor([[-57160.0352,      0.0000, -44910.8438, -96313.3281, -32222.2031]]),\n",
       " tensor([[-104215.0625,  -38303.9688,       0.0000,  -50101.4648, -104389.5312]]),\n",
       " tensor([[-161271.1875, -128354.9375, -123339.2891,       0.0000,  -83093.3906]]),\n",
       " tensor([[-138335.0000, -132855.2031,       0.0000, -145990.0156, -133284.4062]]),\n",
       " tensor([[-2774816.0000, -3095507.2500, -3697047.7500, -3219888.0000,\n",
       "                 0.0000]]),\n",
       " tensor([[  -52.3303, -2288.7341,     0.0000, -3513.9407, -1656.9512]]),\n",
       " tensor([[ -91292.9297,  -73349.4062,  -77188.0469,       0.0000, -161349.4062]]),\n",
       " tensor([[     0.0000,  -4562.5186, -74978.8594, -10911.7617, -35404.0312]]),\n",
       " tensor([[-460384.6250, -128686.4531,       0.0000, -238262.1719, -166811.4062]]),\n",
       " tensor([[-48574.1562, -51193.4180,  -5884.0469,      0.0000, -43782.0234]]),\n",
       " tensor([[-1126950.7500, -4557299.0000, -3246720.0000,        0.0000,\n",
       "           -605381.5000]]),\n",
       " tensor([[-274955.9688, -276413.9062, -367202.3125, -281591.5312,       0.0000]]),\n",
       " tensor([[       0.0000, -5212659.0000, -4388053.5000, -1565954.5000,\n",
       "           -169117.3750]]),\n",
       " tensor([[-5257.4390, -6355.5273, -3915.5779, -5696.7656,     0.0000]]),\n",
       " tensor([[       0.0000, -7614058.0000, -5175257.0000, -2961678.2500,\n",
       "          -1507698.1250]]),\n",
       " tensor([[    0.0000, -5939.2783, -7750.5947, -2496.8271, -3512.0908]]),\n",
       " tensor([[ -98193.9219,  -16568.6914,  -52337.4688, -102763.7812,       0.0000]]),\n",
       " tensor([[-135146.7344, -106732.0781, -113325.0938,  -85433.7734,       0.0000]]),\n",
       " tensor([[-2539.2698,     0.0000, -3203.5332, -6344.5342, -1015.0298]]),\n",
       " tensor([[     0.0000, -83477.0938, -24737.6562, -92960.6406, -69241.2969]]),\n",
       " tensor([[ -89856.7656,  -17529.6719,       0.0000,  -81213.3125, -102663.1953]]),\n",
       " tensor([[-133599.1406,       0.0000,  -31374.8418,  -22507.3535,  -33207.5469]]),\n",
       " tensor([[-48217.6250, -19295.8164, -14833.2773,      0.0000, -20708.6484]]),\n",
       " tensor([[ -4873.5908,      0.0000, -18278.1602,  -6398.8550,  -6480.3267]]),\n",
       " tensor([[ -80735.4844, -143013.3906, -107543.3281,  -25015.5703,       0.0000]]),\n",
       " tensor([[-176198.4062, -121620.3672,       0.0000, -114166.6328, -244388.2500]]),\n",
       " tensor([[-6258.0234,     0.0000, -3795.5674, -4086.3296, -2569.9155]]),\n",
       " tensor([[     0.0000, -33382.2812, -90890.7734, -44172.0469, -96490.7891]]),\n",
       " tensor([[-4800021.0000,  -222401.5000,        0.0000, -9522846.0000,\n",
       "          -4411874.0000]]),\n",
       " tensor([[-55808.1367,  -7805.2695, -65560.2969,      0.0000, -45094.5977]]),\n",
       " tensor([[    0.0000, -3341.0586,  -197.8154, -4330.3511, -4042.1196]]),\n",
       " tensor([[ -44700.1016, -122419.3594,       0.0000,  -68949.3359,  -64038.1680]]),\n",
       " tensor([[      0.0000,  -70929.5234, -132336.2812, -123745.0859,  -40729.4922]]),\n",
       " tensor([[-2736.2727, -2953.2632, -1983.9192, -3883.6157,     0.0000]]),\n",
       " tensor([[-66224.6016, -97267.9688, -27084.2852,      0.0000, -39755.8086]]),\n",
       " tensor([[     0.0000, -48629.8164, -91394.5469, -93939.6484, -33626.5195]]),\n",
       " tensor([[-112875.8906,       0.0000,   -9343.3984,  -57104.1328,  -66009.8906]]),\n",
       " tensor([[-141580.5312, -224303.3750, -101985.3281,  -80184.8359,       0.0000]]),\n",
       " tensor([[  -3525.1289,       0.0000,   -9956.9805,   -4972.2734, -158745.9688]]),\n",
       " tensor([[      0.0000, -109810.4375,  -53496.0547, -148836.8125,   -9730.2852]]),\n",
       " tensor([[ -4402.5840, -40840.8906,      0.0000, -20678.1914,  -2622.0781]]),\n",
       " tensor([[-108531.0000, -111347.6562,       0.0000, -230001.7812,  -32233.4219]]),\n",
       " tensor([[-45493.0469,  -9656.0137, -10917.0703,      0.0000, -30073.2188]]),\n",
       " tensor([[-194126.5625, -213969.4062,       0.0000, -138845.1875,  -66082.8281]]),\n",
       " tensor([[ -46970.2891,       0.0000, -107859.8047,   -6202.2266,    -507.7617]]),\n",
       " tensor([[ -16314.6055, -115531.7188,   -3474.4766, -160420.0938,       0.0000]]),\n",
       " tensor([[-294233.3125,       0.0000, -128222.0625,  -97657.3203,  -18358.2188]]),\n",
       " tensor([[-40720.5195, -32148.8867,      0.0000, -19008.1055, -90854.2109]]),\n",
       " tensor([[-13206.3555,      0.0000, -48994.2812, -43489.0664, -71455.0469]]),\n",
       " tensor([[-316804.5625, -731627.0000, -895430.0000,       0.0000, -606645.3125]]),\n",
       " tensor([[ -3828.4866,      0.0000,  -8117.3853, -12500.1133,  -7062.5352]]),\n",
       " tensor([[     0.0000, -45646.9062, -21564.7441,   -412.1026, -34161.9023]]),\n",
       " tensor([[ -23708.0312,       0.0000,  -11431.1797, -125662.3281, -104943.7578]]),\n",
       " tensor([[       0.0000, -1583671.7500, -1314517.7500, -3767889.5000,\n",
       "          -1938939.5000]]),\n",
       " tensor([[ -40651.6094,  -69083.2812, -154604.8906,       0.0000, -120953.9219]]),\n",
       " tensor([[-3890683.0000, -4020517.5000,        0.0000, -2427934.2500,\n",
       "          -5314230.0000]]),\n",
       " tensor([[    0.0000, -2854.4761, -2798.7839, -5344.0205, -4786.2925]]),\n",
       " tensor([[-2926.3657, -2504.8567, -1977.9769, -2583.9136,     0.0000]]),\n",
       " tensor([[     0.0000, -44253.2070, -58075.3203, -56766.2891, -52326.4844]]),\n",
       " tensor([[-583225.6875, -556312.2500, -204442.3125, -124217.9375,       0.0000]]),\n",
       " tensor([[-55209.6328, -33320.3672, -43137.3828,      0.0000, -12462.7988]]),\n",
       " tensor([[      0.0000, -169100.0625, -164728.1094, -373190.6875,  -64210.8438]]),\n",
       " tensor([[-870885.5625, -201368.8125,       0.0000, -237252.6250, -162371.8750]]),\n",
       " tensor([[ -64277.8633,       0.0000,  -52253.9648, -126311.7422, -114435.9922]]),\n",
       " tensor([[ -36098.5781,       0.0000,  -66947.9844,  -72754.1562, -102082.8125]]),\n",
       " tensor([[-1.9312e+00, -1.3127e+03, -1.5663e-01, -2.0694e+03, -3.2788e+03]]),\n",
       " tensor([[-4730.4839, -1866.8712, -4885.1377,     0.0000, -1308.2567]]),\n",
       " tensor([[ -750.2585,  -613.6018, -4048.2129, -3895.0659,     0.0000]]),\n",
       " tensor([[-204575.0312,  -55762.2930, -145131.0156,       0.0000, -102870.8750]]),\n",
       " tensor([[-1779.4065, -3997.6787, -3537.3430, -3337.1553,     0.0000]]),\n",
       " tensor([[      0.0000,  -96809.4375, -123927.0234,  -39680.6250,  -59141.2578]]),\n",
       " tensor([[-4365.8696, -6357.9473, -3028.8718, -3816.6650,     0.0000]]),\n",
       " tensor([[-5046480.0000, -4484239.5000, -1150488.8750,        0.0000,\n",
       "          -4982015.0000]]),\n",
       " tensor([[        0.0000, -10260930.0000, -12339378.0000,  -8282174.5000,\n",
       "          -11244505.0000]]),\n",
       " tensor([[-1728.7084,     0.0000, -4120.9395, -6298.8418, -2792.7009]]),\n",
       " tensor([[-105591.5156,  -19668.2109,   -3759.1680,  -31950.6680,       0.0000]]),\n",
       " tensor([[      0.0000, -161991.7188, -370413.8750, -198672.4219, -197940.9531]]),\n",
       " tensor([[-12658.1914, -11085.5605,      0.0000, -15699.8379, -14639.2070]]),\n",
       " tensor([[-5448.9463, -4752.5093, -4763.3979, -6413.3931,     0.0000]]),\n",
       " tensor([[-1008.4196, -4999.9902, -2471.8684,     0.0000, -4361.1074]]),\n",
       " tensor([[-2392.1287, -1183.3105,     0.0000, -5965.8130, -4153.9355]]),\n",
       " tensor([[-1101822.2500, -2136981.0000, -2718477.2500,  -689049.2500,\n",
       "                 0.0000]]),\n",
       " tensor([[-18624.3184, -20402.6406, -10288.1152,      0.0000, -94462.2656]]),\n",
       " tensor([[-82427.8359, -50723.3594, -66473.3984,      0.0000,  -1217.6465]]),\n",
       " tensor([[-148110.0938,  -75931.9688, -159726.5156,       0.0000,  -93625.7891]]),\n",
       " tensor([[ -74337.4766,       0.0000, -111446.9062, -140163.8125, -108940.3906]]),\n",
       " tensor([[-3572.8535,     0.0000,   -66.5583, -2503.9348,  -990.4954]]),\n",
       " tensor([[-196485.9219,       0.0000,   -9651.4531,  -24474.5703, -163011.3750]]),\n",
       " tensor([[      0.0000, -103548.0234,  -57573.2148,  -74481.4766, -111297.8750]]),\n",
       " tensor([[ -93160.2500,  -64365.1562,       0.0000, -177151.1562, -190383.7812]]),\n",
       " tensor([[-3265.9180, -2255.6543,     0.0000, -1760.1367,   -47.3407]]),\n",
       " tensor([[-143040.7188,       0.0000, -651353.1875, -213937.3750, -228179.5938]]),\n",
       " tensor([[-123789.9453,  -53036.7930,  -33722.3477,       0.0000,  -77183.3906]]),\n",
       " tensor([[-132973.9688,       0.0000,  -37549.1914,  -85705.0312, -111213.8516]]),\n",
       " tensor([[-102645.3125, -103142.0312,       0.0000,  -91866.3750,  -65307.4766]]),\n",
       " tensor([[-1415.7665, -1484.5308, -1389.4355,     0.0000, -1429.9927]]),\n",
       " tensor([[ -27788.1016, -115859.4844,  -31433.4160,       0.0000, -153861.7812]]),\n",
       " tensor([[    0.0000, -3215.7485, -1875.0161, -2441.6653,  -916.8384]]),\n",
       " tensor([[-69350.9297, -61643.6562,      0.0000,  -6473.5244, -26023.9453]]),\n",
       " tensor([[    0.0000, -7874.0703, -2389.8230, -6086.9839, -3945.0820]]),\n",
       " tensor([[      0.0000,  -10851.5703,  -47092.0039, -218434.3594,  -83598.6562]]),\n",
       " tensor([[-3813916.5000,        0.0000, -4241403.0000, -7274784.0000,\n",
       "          -7644645.0000]]),\n",
       " tensor([[-849424.1250,       0.0000,  -31908.5000, -808676.2500, -770596.3750]]),\n",
       " tensor([[ -97168.9531, -104003.4375, -272859.7188,       0.0000, -195107.7656]]),\n",
       " tensor([[      0.0000, -117867.4922, -128235.2344, -173404.0469, -247010.3594]]),\n",
       " tensor([[ -520.7483,   -49.5720,     0.0000, -2703.4192, -1419.9268]]),\n",
       " tensor([[ -28853.0391,       0.0000,  -20271.3750, -115789.2500,  -40188.0820]]),\n",
       " ...]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = [F.softmax(logit, dim=1) for logit in nodes_data]\n",
    "predicted_classes = [torch.argmax(prob, dim=1).item() for prob in probabilities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.20\n",
      "Precision: 0.64\n",
      "Recall: 0.20\n",
      "F1 Score: 0.27\n",
      "Confusion Matrix:\n",
      "[[341 342 352 339 326]\n",
      " [ 22  20  20  18  24]\n",
      " [ 24  10  16  27  24]\n",
      " [ 21  25  23  16  27]\n",
      " [ 22  19  30  13  25]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "# Example true labels (replace with your actual labels)\n",
    "true_labels = y\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_classes)\n",
    "precision = precision_score(true_labels, predicted_classes, average=\"weighted\")\n",
    "recall = recall_score(true_labels, predicted_classes, average=\"weighted\")\n",
    "f1 = f1_score(true_labels, predicted_classes, average=\"weighted\")\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_classes)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming nodes_data has shape (num_samples, num_nodes, num_features)\n",
    "# Aggregate node features by averaging or summing them\n",
    "nodes_data_flat = [np.mean(data.numpy(), axis=0) for data in nodes_data]\n",
    "\n",
    "# Convert to numpy array\n",
    "nodes_data_flat = np.array(nodes_data_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.7999916e+03, -5.3306616e+03, -1.7410391e+03, ...,\n",
       "        -4.1084238e+03, -4.8195980e+04, -3.0416002e+06]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_data_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7911\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.99      0.88       338\n",
      "           1       0.00      0.00      0.00        19\n",
      "           2       0.00      0.00      0.00        24\n",
      "           3       0.00      0.00      0.00        28\n",
      "           4       0.50      0.06      0.11        17\n",
      "\n",
      "    accuracy                           0.79       426\n",
      "   macro avg       0.26      0.21      0.20       426\n",
      "weighted avg       0.65      0.79      0.70       426\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "nodes_data_flat = np.mean(nodes_data, axis=1)\n",
    "y = np.array(y)  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    nodes_data_flat, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 4, 4, 4])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "# Define the Autoencoder model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128), nn.ReLU(), nn.Linear(128, latent_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, input_dim),\n",
    "            nn.Sigmoid(),  # Assuming input data is normalized between 0 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded, encoded\n",
    "\n",
    "\n",
    "# Parameters\n",
    "input_dim = nodes_data_flat.shape[1]\n",
    "latent_dim = 50  # Number of dimensions in the compressed representation\n",
    "\n",
    "# Initialize the autoencoder\n",
    "autoencoder = Autoencoder(input_dim=input_dim, latent_dim=latent_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
